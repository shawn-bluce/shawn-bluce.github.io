<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>所有文章 - Shawn's blog</title><link>https://blog.programmer.work/posts/</link><description>所有文章 | Shawn's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>shawnbluce@gmail.com (Shawn)</managingEditor><webMaster>shawnbluce@gmail.com (Shawn)</webMaster><lastBuildDate>Fri, 02 Jan 2026 13:52:43 +0800</lastBuildDate><atom:link href="https://blog.programmer.work/posts/" rel="self" type="application/rss+xml"/><item><title>2025 年度总结</title><link>https://blog.programmer.work/posts/2025-summary/</link><pubDate>Fri, 02 Jan 2026 13:52:43 +0800</pubDate><author>Shawn</author><guid>https://blog.programmer.work/posts/2025-summary/</guid><description><![CDATA[<h1 id="0x00-intro">0X00 Intro</h1>
<p>兄弟们，又活了一年～</p>
<p>这是我的第七个年度总结，在 <a href="/posts/2019-summary/" rel="">2019年度总结</a> 年度总结的开头我说：“2020年要来了，听起来这是个多科幻的年号啊。《银翼杀手》里说2019年底人类就有强人工智能了，可以穿梭宇宙了，甚至可以星际殖民了。然而现在就是2019年最后一天了，我的小爱同学还是像智障一样经常听不懂我说话。” 现在 2026 年已经来了，如果有机会对当时写 2019 年度总结的我说点什么的话，我估计会说：<!-- raw HTML omitted -->“告诉所有信任自己的朋友，多多多多囤口罩、食材、水和各种必需品”<!-- raw HTML omitted --></p>
<p>不开玩笑了，现今虽然普通的小爱同学还是不太能听懂我们说话，但是如今的大语言模型已经极大的融入了我们的生活，应该没有人会说 ChatGPT 和豆包听不懂人话了吧。</p>
<p>说起来今年发生在我身上的变化还是非常多的，年初的订婚、找房搬家、装修、装修公司跑路、搬家、辞职、换工作、三十“大寿”&hellip;&hellip;</p>
<p>我的年终总结文章是每年最长的博客内容，但也是最没有章法的，主打一个意识流，那么现在总结开始。</p>
<h1 id="0x01-压力大事件">0X01 压力/大事件</h1>
<p>今年是最近几年中压力或者说内耗最大的一年。我一直觉得“就这点事，怎么就把我压的够呛呢？我不应该觉得累，因为比我难的人还有非常非常多，我这点事情不配累”。就是因为我的这种并不健康的想法，会让我陷入一个内耗循环：事情太多-&gt;觉得累-&gt;觉得自己不配累-&gt;内耗-&gt;变累-&gt;觉得自己不配累-&gt;内耗-&gt;变累&hellip;&hellip;我之前遇到这种事情都可以靠我自己比较强大的自我调节能力迅速恢复，<strong>但是这次不一样了，我没能恢复</strong>。</p>
<p>在经过某次跟 Claude 聊天后才反应过来：订婚、从工作了 5 年的公司离职、适应新工作、装修、装修公司跑路、30岁节点这些都是很大的事情，每一个都会很大程度上的消耗人的精力。而兄弟我，一年里全给干了 🤔</p>
<p>嘴上说好像是打破了这个内耗循环，但其实直到现在我都还有这种想法：“订婚、离职、新工作、装修、没钱花、30 岁这些事情难道不是所有人都会遇到的吗？怎么没见别人这么大压力，果然还是我自己太弱了”</p>
<p>好了，下面开始逐一介绍一下今年经历过的一些人生大事件，和人生大压力吧。</p>
<h2 id="订婚">订婚</h2>
<p>今年的春节是我 30 年人生中第一次没在家里过年，因为父母过来了要去女朋友家里，赶在两方家长都有空的情况下举行订婚宴。要提前跟双方家长和女朋友沟通各种细节，采买各种东西，提前找合适的餐厅（选在除夕前一天，位置都很难定）等等等&hellip;&hellip; 好在最后双方家长见面非常顺利，订婚宴也非常顺利，就这样我成了一个有婚约的男人 👨</p>
<blockquote>
<p>说起来，之前看知乎上的有关第一次见家长、双方家长见面、订婚之类的问题，感觉这种场面简直是堪比《让子弹飞》中的“鸿门宴”，说错一句话做错一个动作就会带来<!-- raw HTML omitted -->杀身之祸<!-- raw HTML omitted -->天大的后果。但实际发生在自己身上之后才明白，如果自己的女朋友是个好女孩，双方家长也都能好好交流，都能以自己儿女为重，那不管是我们去见家长还是双方家长会面，甚至是后面的订婚结婚和一系列的事情都可以很轻松，很简单。</p>
</blockquote>
<p>中间比较好玩的一件事是女朋友家里那边有一个习俗：订婚的时候男方要送两只完整的大猪肘。而我和我爸妈大老远跑过去很难在一个下午找到两只完整的大猪肘。后面在一个规模比较大的永辉超市猪肉摊位问，工作人员的那个阿姨也是说没有整个猪肘卖。但是那个阿姨好奇心比较重，问了一下说为什么要买两个大猪肘，我们说了之后阿姨贼兴奋，说：“那不行，我得想法给你们整”。然后阿姨就直接冲到库房里扛了半扇猪，硬生生给我们剁了两个大猪肘，还特意祝我们订婚顺利 🤣</p>
<h2 id="装修">装修</h2>
<p>装修这件事下面有一个单独的章节，这里就简单带过。在决定年后开工之后，我们其实提前很早就在逛宜家和相关的家具/建材市场了，也提前制定了一个巨详细的预算清单。都说装修的预算几乎会花掉 150%，但由于我们（装个逼，主要是我）的预算清单非常非常详细，详细到墙上需要几个 86 盒，对应的 86 盒在闲鱼上卖多少钱都有标注（是的没错，我们装修有不少东西是在闲鱼买的）。所以最后我们虽然也超了预算，但超了不到 20%，应该已经算很强了吧。</p>
<p>剩下还有更多的细节问题就留在下面专门的章节再说吧。</p>
<h2 id="工作变动">工作变动</h2>
<p>工作变动是突如其来的，今年三四月份的时候公司突然开始实行一些新的规章制度。纯是因为这些制度的话还不会直接难受到需要跑路，<strong>但是</strong>，我确实也在公司干了四五年了，从薪资角度来说只涨过一次，从技术角度来说好像没找到太多提升的空间（当然这有挺多一部分是我个人原因），再加上这时候如果拒绝这个新制度的话是一定会被解除合同的，这样一来就能拿到一笔 N+1 的赔偿款（用于装修）,所以我多加思索之后还是决定离开了瑞数。</p>
<blockquote>
<p>这里要做一个声明，在瑞数工作的这几年还是很舒服的，不管是工作内容和工作量，还是同事领导之间的关系都非常舒服。这里选择离开纯纯是我的个人原因。</p>
</blockquote>
<p>记得之前 2019 年的时候，周围同事在说“互联网寒冬”来了，当时的我觉得这不挺好的嘛，哪里就寒冬了？但是从这次找工作来说，还是挺明显的，不过这次不是“互联网寒冬”，而是正经的“寒冬”了。这次找工作的时候明显觉得难找，很多都是外包和外派，也会有一些 6 个月的短期工作。希望以后大家找工作都能找到那种薪资上涨一些、社保公积金全额缴纳、不怎么加班、能带来个人提升的工作（怎么听起来这就是一份<strong>正常</strong>的工作呢）。</p>
<p>从瑞数离职之后和到现在新工作之前有过一段工作上的<strong>趣事</strong>，下面会单独提。到了现在这里之后就是一份平平无奇的工作了，好处就是工资实打实变多了，技术栈的选择也更加自由了（这两项正是我选择现在这家公司的主要原因），但问题就是团队的核心是运营和业务，我们开发只是给大家打辅助的，所以并不存在产品设计和技术积累的说法。再加上没有软件团队的基本研发流程，就导致明明一个大几百人的公司工作起来像是一个十来个人的小作坊一样。</p>
<p>本来我在这家公司干了这小半年挺煎熬的，但正是我觉得即将绷不住的时候反而看开了，觉得既然已经绷不住要跑路了，那不如逼自己一把，看看自己在这种环境下能做到什么程度。所以现在我跑路的想法反而减弱了一些，想要挑战一下自己，在这种并不算好的环境下能不能以自己的能力尽量扭转事态（听起来又是在给自己强上压力）。如果成功了，那我相当于保住了这份工资还说得过去的工作，之前不熟悉的专业技能也得到了锻炼。哪怕是最后失败了，结果也不会比我现在离职更差，而且无论成功与否，我的这段尽力扭转事态的经验都将会是我工作生涯中提升软实力的一个强有力的助推剂。</p>
<h2 id="装修公司跑路">装修公司跑路</h2>
<ul>
<li>好消息：“硬装要结束了”</li>
<li>坏消息：“装修公司跑路了”</li>
</ul>
<p>是的没错，网上一直流传的各种装修公司跑路的事情，即使是我们想尽办法避免了，最后还是发生在了我的身上。不过虽然装修公司跑路了，但我们好在提前做了一些准备，比如装修款是分成 6 次付的，并且主材和门窗等所有可以自己买的我们都自己买了。公司跑路的时机对我们来说也还算是不幸中的万幸，是在我们装修公司做完事需要收款的时候跑的，导致我们没有因为装修公司跑路这件事有直接的金钱损失。所以虽然公司跑路了，但是对我们的实际影响并不大，只是“质保”这个本身就不太存在的东西，现在彻底消失了。</p>
<p>如果后面有朋友需要装修，尽可能还是把付款分成尽可能多次，6 次 8 次不嫌多，这样万一公司跑路的话也可以尽可能让自己的损失小一些。</p>
<h2 id="三十大寿">三十大寿</h2>
<p>几年前朋友王哥过三十“大寿”的时候，我觉得他比我大好几岁，三十岁这个事情离我还有点遥远，结果时间就这样 kucha 一下过去了，我也三十了。</p>
<p>孔子说“三十而立”，我小时候觉得意思是“三十岁的时候儿子应该能站立起来”，不过显然不是这么个意思。实际上这句话的大致含义是“三十岁的时候，应该在品德、事业和人生方向上自立自强、站得住脚”。但是这句话也还是有点虚，我就让 AI 总结了一下，GPT-5 给出的答案如下：</p>
<ul>
<li>有稳定的工作和收入，能独立处理生活中的事务</li>
<li>明确的人生目标和价值取向，能坚持原则不轻易被动摇</li>
<li>能独立面对困难，不依赖父母或他人提供一切</li>
</ul>
<p>这么说来我应该大概也许能配得上“三十而立”吧（除了买房的时候父母凑钱出了首付的大头，没错，这件事总会让我觉得我其实不够“立”，觉得自己没能全靠自己搞定一切）。</p>
<p>要说三十岁有什么感受吗？好像也没有，而且我这个人一直都没什么仪式感，在我 25 岁之前的生日里，有生日蛋糕的次数应该不超过 5 次，生日礼物也一样。所以不管是之前 18 岁的生日，还是后面 20 岁乃至这次 30 岁的生日，都没有很特别的仪式或者什么的。不过这次不同于之前 18、20、25岁的生日，这次有女朋友送的生日蛋糕和生日礼物了 🎉。本来说这次趁着这个 30 周岁的由头送自己一个平时不舍得买的礼物，但是转念一想平时不舍得买不就是不太值得买吗？那为什么要在生日这天送自己一个挺贵但又不太值得买的东西呢？所以纠结了一段时间后还是放弃了这个想法。说到这里，突然感觉自己好朴实啊，我看很多人都可以找到由头送自己一些礼物，我连自己三十岁生日的礼物最后都没舍得买 🤣</p>
<h2 id="有关压力">有关压力</h2>
<p>我思考了很久不知道这里应该怎么说。有几个版本：</p>
<ul>
<li>我是一个对自己要求很高的人，只要压力压不夸自己就觉得自己还不用休息</li>
<li>我一直觉得自己压力挺大的，但是又总是觉得只要还压不死自己就总想给自己上强度</li>
</ul>
<p>但是又反过来想：“就我？还对自己要求高？要求高连个好大学都考不上？要求高连个互联网大厂都进不去？我压力还大？年轻人不都这样吗？我收入还不错，父母也不添乱，我配谈压力？”就这样仿佛循环，让自己压力越来越大，也越来越焦虑。我会有哪些焦虑问题呢，比如说上一天班回家本来可能挺累的（没错又来了，我甚至觉得自己好像也没有很累），但是如果玩一晚上游戏就会觉得“浪费时间”了，就得整点有意义的事情做，哪怕是看看B站也得翻出那些小Lin说、王骁之类的视频“学习”，虽然很有可能完全听不进去。但是视频放在那里，我就有一丝丝的安心。不过也有失灵的时候，我曾经有时候一个视频看完直到自己其实没看进去，那就坐在电脑前面再看一遍，结束后发现还是没看进去，就再看一遍。三遍结束后可能一个半小时就过去了，但还是没从视频中“学到什么东西”。</p>
<p>我第一次直面压力其实还得感谢 AI 的出现，当时是给自己报名了软考高级架构师的的考试，但是由于备考时间不多，再加上工作的事情很心烦，就导致准备的并不是很充分。开考前一个月的时候我就想直接放弃考试了，可以让自己轻松一些，不用每天下班回家看三个小时视频课程。但后来还是没有放弃，又继续逼着自己回家之后“学习”（我都不好意思管当时的状态叫学习），直到考试前两天我定了考场周围的住宿，那时候我觉得我能考过的概率不超过 30%，而且当时整个人的状态极差。我就花了挺长时间跟 AI 聊了我的压力、焦虑以及这个考试，最后我把那个酒店退掉了。在本该去考试的那天，约着朋友一大早跑了七十多公里去吃包子，然后在自己最熟悉最放松的地方休息了一整天，才感觉自己的电量逐渐开始回升。</p>
<p>令我印象深刻的是当时我退了酒店后跟 AI 说：“我已经把酒店退了，谢谢你的开导”，没想到的是 AI 回答我说：“你不用感谢我，真正应该感谢的是直面人生并做出正确决定的你自己” 😮‍💨</p>
<h1 id="0x02-旅行">0X02 旅行</h1>
<p>好了，说完沉重的话题该说点快乐的了。</p>
<p>今年我和女朋友同时离职后，我们的 5 人小群就只有一个人还有工作了<!-- raw HTML omitted -->不是说好说点快乐的吗<!-- raw HTML omitted -->。所以四个没有工作的人就想出去放肆一把，时间选在劳动节假期之前的小淡季，目的地选在了很难有机会去一次的新疆。</p>
<p>不得不说，新疆真的太大太漂亮了，这里 po 出来一些照片就好了，没有过多的赘述。</p>
<p>我们的行程大致是：成都卧铺到乌鲁木齐（队员有人想试试长途卧铺火车），乌鲁木齐租车开到赛里木湖，自驾游玩赛里木湖/果子沟，自驾游玩库尔德宁，自驾游玩那拉提，<!-- raw HTML omitted -->自驾游玩火焰山，因为堵车没去成<!-- raw HTML omitted -->，游玩天山天池，最后飞回成都。</p>
<p>如果需要一些建议的话：</p>
<ul>
<li>我们这个线路不错，但是有优化空间：可以直接飞伊宁，自驾游玩赛里木湖、库尔德宁、那拉提，结束后高铁回乌鲁木齐</li>
<li>卧铺火车非必要不要坐，确实太慢了，太耽误时间</li>
<li>至少要有两个人能开车，还是那句话，新疆太大了</li>
<li>租个空间大点的车，真有四个人玩一周的话东西还是非常多的</li>
<li><!-- raw HTML omitted -->不要租橙色的坦克300，不然你会在景区一堆橙色的坦克300中迷失自我<!-- raw HTML omitted --></li>
</ul>
<p>去新疆旅行的时候有一个小插曲，就是当时在赛里木湖出来之后发现距离霍尔果斯口岸很近，本着<strong>来都来了</strong>的原则就去了。然后继续是<strong>来都来了</strong>那不得出个国？大家就办了临时手续，直接去了趟哈萨克斯坦🇰🇿。而且，这是我第一次出国。没错，我第一次出国的目的地不是常见的日本韩国东南亚，而是哈萨克斯坦&hellip;&hellip;整个“出境游”的体验怎么说呢，除了中国国门就见到了个前苏联国门，唯一的感触就是过了国境线对面明显是极度荒凉的 🤣</p>
<p>这个小插曲的中间还有个小插曲的小插曲。因为徒步走过去走不了几步，所以大家都是坐车去边境另外一边转一圈回来的，我们的司机师傅开在哈萨克斯坦的荒凉的路上的时候跟我们强调了几遍：“现在已经出了中国边境了，警察过来也没有执法权，军队更是没发过来”。他越是强调这个事，我们就越觉得他是不是对我们有所图，给两个女生吓得差都没敢下车 🤣</p>
<h1 id="0x03-装修">0X03 装修</h1>
<p>装修，装修可是个大事。</p>
<p>先从租房说起：本来说尽可能租近一些，然后在附近小区看了看，感觉也不是很喜欢。直到遇到后来租下的这个房子，这个房子就在我自己这个单元的楼下，当时中介带我们去看了之后感觉还不错，心想到时候搬家和监工都方便很多。但是，但是的是我们只租半年的情况下中介要收我们 2700 块也就是一整个月的中介费，我就有点纠结。后来我突然想起来<strong>既然是我楼下的房子，那房东岂不是就在业主群？？？</strong> 反手掏出手机找到业主群，然后找到那个房东加微信。简单聊两句就成功免掉了 2700 的中介费，还用之前租客 2500 的价格租下来了，最后租了八个月相当于怒省 <code>(2700 - 2500) * 8 + 2700 = 4300</code> 元。还不止，由于租在了同个单元的楼下，所以装修公司是没找的，就自己搬着东西靠电梯一趟趟搬完了，又怒省几百 🎉</p>
<p>说到装修，其实我更想分享的反而不是硬装软装这些，而是：组网和电器选购（不愧是典型程序员）。之前都是租房，甚至是合租，对家里的网络从来没有什么主导权，这次终于翻身把歌唱了，可得好好整一下家里的网络。本来想的是直接墙里埋 CAT 7 的网线，但后来考虑了一下还是放弃了，不过我还是给每个房间都准备了 2.5G 交换机，保证家里所有的有线设备都可以通过 2.5G 接入（主要是为了高速访问 NAS）。</p>
<p>电器选购的话电视就不说了，这东西不线下看是很难准确传达的。就从冰箱开始吧，我算是第一次了解到冰箱和冰箱之间的差距了。因为我家里比较小，只能买些小冰箱，最初看的一些冰箱只有 200L 多一点，后来发现东芝的小白桃，体积差不多的情况下容积直接翻倍到 400L 多一点了，后来我们选的松下也是一样。可能也是我之前确实没什么见识，第一次打开这种六七千块钱的小冰箱的时候，感觉外壁好薄，内部空间真的好大 🤯。电视音响也是，闲鱼上花了 1500 块买了两只 TCL 的 Z100，怎么说呢，如果空间允许我还想买两个后置换绕。对于现代电视来说，声音系统的提升其实比画质提升更敏感，起码对我来说是这样的。在玩 GT7 的时候是能正经听到 V8 和 V12 的轰鸣声的。</p>
<p>最后就是家务机器人，扫地机和洗碗机简直就是人类救星。前者我买的是扫拖一体、自动上下水、自动集尘加自动清洗烘干拖布的（说白了就是能自动就自动）。好用程度怎么说呢，到现在为止四个月了，只清理过一次扫地机，其他时候都是它在每天清理地面。后者就是一个平平无奇的洗碗机，但对我来说洗碗机给我最大的幸福感反而不是吃完饭丢进去洗碗的这个点，因为这个点是在买洗碗机之前早早就知道的。最大的幸福感反而来自于做饭的时候，以前总是想着节省一个盘子一个碗，就可以少洗一个，现在则有了“随便用盘子和碗的底气” 🤣</p>
<h1 id="0x04-专业知识">0X04 专业知识</h1>
<p>今年实在是没有时间单独去学习一些专业知识和技能，只是偶尔会抽些时间学一下，但是都不怎么成体系。不过前面说到在现在这家公司很难收获到东西，但我还是尽全力给自己搞到了一点“好处”。因为目前我们这个组就只有我一个后端开发，所以技术栈的选择和各种设计都是我一个人说了算，那我可就放飞自我了。</p>
<p>在之前启动一个新项目的时候，我就把最近比较热门的 FastAPI 整上了，最近也把流行的 uv 包管理整上了。按照之前的经验来说，以我当时对 FastAPI 的了解是绝对不足以支撑真正的业务开发的，但现在时代变了，我一边开发、一边看文档、一边跟 AI 对谈，学习 FastAPI 的效率简直是“如<!-- raw HTML omitted -->壁<!-- raw HTML omitted -->虎添翼”。再加上我之前 MySQL 的水平一般，到了这边由于需要处理的数据量比较大，所以 SQL 和数据库设计的能力也明显提升了。Redis 的水平也是，从初学者水平在短时间内提升到了熟练水平。</p>
<p>只是目前还没有机会把 Go 也整上，目前我 Go 的水平还是不咋样。后面有机会了要把 Go、MQ 甚至是 LLM 和 RAG 都一并用上。</p>
<p>AI，是的，现在连年度总结都离不开 AI 了。如果说 OpenAI 发布 GPT-3.5 的 2022 年是 AI 元年的话，那今年真的就是 AI 爆炸年了。我一度以为 DeepSeek R1 是挺久之前的事情了，但实际上它是今年才刚刚发布的。今年这一年下来光是我自己的工作流就从 POE 到 CherryStudio 再到 Open WebUI + OpenRouter 进化了两次了。最近又开始用 Claude Code 了，感觉程序员的工作和学习方式已经极大的被 AI 改变了。</p>
<p>虽然这波 LLM 热潮已经开始三年多了，但我对 LLM 的理解和学习反而在 2025 年是最多的。同时学习到的这些知识真的很直接的反哺了我的日常工作、学习和生活，所以我计划明年再在 LLM/AI 上投入更多的时间。</p>
<h1 id="0x05-游戏">0X05 游戏</h1>
<p>今年虽然算是游戏大年，但是我自己玩的游戏其实没有很多，但是每一个质量都还挺高的。今年最早玩的是三国无双起源，不开玩笑地说这是我打通关的第一作三国无双，之前的都是偶尔玩玩，或者直接下一个全角色解锁存档，然后选关随便玩。不过这一作最大的槽点就是加入了“主角”，我都玩三国无双了，显然不是很有兴趣这个纯虚构出来的“主角”，起码这个“主角”的剧情实在是有点多了。</p>
<p>其次就是双影奇境，作为 Fuck Oscar 的新作，品质一如既往的很棒。印象最深的就是看早先评测的时候说：“最后一关是电子游戏史上从来没有出现过的东西”。本来我是持怀疑态度的，但是真到玩了最后一关之后，我也想说<strong>双影奇境的最后一关是电子游戏史上从来没有出现过的东西</strong>。</p>
<p>再者就是三角洲行动，这个游戏是在离职休息期间接触到的，跟朋友打了一段时间大战场，发现这个游戏模式还不错，正好这时候战地6 beta测试开始了。本来腾讯可能想的是“战地卖那么贵，我免费，肯定能吸引很多玩家”，但是我想的是”这模式这么好玩，我倒要看看原版有多好玩“，然后 <!-- raw HTML omitted -->¥268<!-- raw HTML omitted -->。怎么说呢，战地确实比三角洲更好玩，而且没有排位积分，不用有什么上分的心理压力。如果要说战地哪里做的非常好的话，我自己总结下来就是<strong>战场氛围</strong>和<strong>战争纪实 V.A.L</strong>音效。三角洲的画风和战场氛围给人的感觉就是比较真实的小孩过家家，战地的战场渲染和战争纪实音效结合起来真的是战场感拉满。</p>
<p>然后是羊蹄山之魂，作为对马岛之魂的续作我对它还是非常满意的，延续了之前对马岛之魂的各种优秀体验。如果说有什么是我自己不满意的部分，那主要就是两点：<strong>女主角是在是有点丑</strong>，以至于我第一时间关闭了“剧情中隐藏头盔”；另外不满意的就是插入了太多获取武器的支线任务，武器之间有相互克制关系，如果不去做支线任务就会缺失针对某一类敌人的优势武器，去做又会发现很多任务极其相似 🤷‍♂️</p>
<p>最后是苍翼：混沌效应，这个游戏就非常非常适合我。它是一个国产 rogelike，难度可以说是对手残人士很友好了，画面又非常酷炫，尤其是结合 miniLED 显示器的 HDR 效果，绝佳。这游戏质量很高，但是早期销量不行，本来制作组都绷不住了，但是被玩家发现后自发宣传，然后靠大家又给买活了 🤣</p>
<h1 id="0x06-电影">0X06 电影</h1>
<p>说完游戏来说电影，就按时间顺序说吧。</p>
<p>今年争议最大的电影一定是《哪吒：魔童闹海》了，从我的视角来看这是一部不错的电影，但是魔怔人太多了，有人说它强无敌，有人说它烂到没边。正常来说这部电影的品质肯定是配不上这个票房的，但也不至于像某些人说的一样不堪入目吧。</p>
<p>其次是我之前看过的《孤独摇滚》，这个怎么说呢，我不知道把 TV 版重新剪一下再换个音乐就当剧场版上是不是正常操作，反正是把我看懵了。最开始我还以为是前情提要呢，结果一直提要到最后结束，故事还没讲完，只是个“上” 🤷‍♂️</p>
<p>然后是去看的《F1：狂飙飞车》，个人评价能给到 8 分，其中整体剧情勉强合格，视觉表现力拉满，音乐拉满（汉斯季默，牛逼），美式插科打诨和强行谈恋爱有点俗套。个人评价这个电影还算是一部特效片，所以如果已经错过了院线期想再看的话，就尽量还是把时效音效尽量整好一点观看比较好。</p>
<p>再然后就是重映的老电影《攻壳机动队》，是挺好看的，只是从 2025 年看没觉得有多惊艳，可能放在当时的历史条件下确实很强吧（就像我之前读过的《克莱因壶》一样）。</p>
<p>下一个就是今年最期待的电影《你行你上》，不能说这是个烂片，但也确实有负我对姜文这么长时间的期待。</p>
<p>再然后就是《鬼灭之刃》，但离谱的是我一集 TV 版都没看过，这剧场版进去就是咔咔战斗，然后继续咔咔战斗，后面稍稍讲了个故事，就又是咔咔战斗，太顶了。对于我这种没看过 TV 版的人来说有点不友好，但如果看过 TV 版的话，应该是一个非常非常爽的剧场版了。另外再补充一句：<strong>我永远喜欢 Dolby Cinema</strong>。</p>
<p>今年看的最后一部电影是《阿凡达 3：火与烬》，电影只能说就那样，但是这个 CINITY LED 真的是太顶了。看过这么多场 3D 电影，我以为 Dolby Cinema 的亮度已经很离谱了，结果这个直接整了个 LED 屏幕，真的是第一次看亮度和对比度这么高的电影，这个技术真的太强了。</p>
<blockquote>
<p>woc 我发现印象深刻的电影有一半以上都是动画，我不会成二次元了吧 🤯</p>
</blockquote>
<h1 id="0x07-摄影">0X07 摄影</h1>
<p>前两天整理相册的时候发现，今年一整年用相机拍的照片（筛选后导出的才算）虽然有 700 张，但是去掉帮朋友拍摄婚礼留下来的一些，和去新疆旅行时候大量拍摄的之后就只剩下 300 多张了。所以今年确实是没拍多少照片。但是今年付费报名了大马猫本的线上摄影课（最国际化的一次，大马老师在澳大利亚，同学有中国、东南亚、欧洲、美国的，大家顶着时差上课）。这个课本身其实是比较基础的，但还是明显有一些收获，比如终于整明白怎么样的曝光是合适的、怎么样正确选择白平衡了。这东西怎么说呢，就类似于是自学的程序员终于上了几节专业课，把自己本以为明白的事情真的搞清楚了。</p>
<p>另外就是今年有一个镜头升级方案：</p>
<ul>
<li>把美科 85mm F1.4 升级成了美科 85mm F1.8，因为半档光圈对我不重要，但体积变小很明显</li>
<li>把适马 35mm F2 自动对焦，升级成了 ZEISS 纯手动对焦的 35mm F2，因为我发现我的 35mm 主要是“拍着玩”在用，和给我自己提供一种“我很屌”的心理 buff，那不如整一个更好玩且逼格更高的纯 ZEISS 手动头来用</li>
<li>把腾龙 28-200 升级成了索尼 20-70G，这算是实打实的升级，画质得到了明显的提升，广角也足够用了</li>
</ul>
<h1 id="0x08-运动">0X08 运动</h1>
<p>本来的计划上今年要开始跑步和骑车，但是怎么说呢，确实也跑了，确实也骑了，但这个量远远没有达标。本来今年是有一个 200km 的骑行项目的，但是并没有完成，只完成了一次 150km 的。跑步也是一样，之前说要不试试在 30 岁生日那天完成一次 30km 的长跑，但后来也只是尝试过几次 10km 跑。</p>
<p>不过也正是这几次对我个人来说的“高强度运动”，让我认识到了一个问题：“人的恢复能力和鸣人是有差距的”。第一次完成 10km 的晚上，心跳一直一直降不下来，直到运动完两三个小时洗完澡躺床上了，心率还是维持在 100 出头（我确实太菜了）。不过对我个人来说跑步就是单纯的运动，骑车则是在运动的基础上显著的加了快乐。</p>
<p>2025 年在运动上投入的时间还是太少了，这次 2026 年必须要加把劲了。</p>
<h1 id="0x09-趣事">0X09 “趣事”</h1>
<p>好了现在终于可以开始说前面工作变动里提到的<strong>趣事</strong>了。我就不啰嗦了，事情是这样的：我在找工作的时候本身是直接拒绝外包的，但是中间有一个比较大的外包公司联系到了我，岗位是字节的火山引擎的相关项目外包，并且给出的薪资是我比较满意的。那我一看有机会跟大厂员工一起工作（应该能学到些东西），并且薪资也不错，再加上我当时也确实找了一段时间工作了，考虑过后就接受了那份 offer。</p>
<p>事情就从入职前一天说起：之前 HR 通知的工作时间是早上九点半开始，我就准备九点半到公司报道。幸亏前一天晚上我多问了一嘴，说“我是明天早上九点半到公司报道吧”，这时候 HR 回我“不是的，你明天得九点到岗”。这时候其实就已经有点怪了，因为 HR 前期并没有跟我说到岗时间，还是我提前问的，得亏我问了，否则第一天就会“迟到”。时间快进到第二天早上入职，我准时到了公司后在前台旁边沙发坐了半个小时左右才有人来接待我，到会议室里和几个其他的同事一起接受入职培训和签合同，就在签合同的时候发生了<strong>我三十年里见过的最离谱的事情</strong>（之一）：有一个一起办入职的同事伸手去拿会议室桌子中间的一瓶矿泉水），同时说到：“我有点渴，这个水可以喝吧”，结果 HR 说：“不行，<strong>这个是给领导准备的</strong>，一会儿你去外面拿个纸杯接水喝吧”。</p>
<p>当时我几乎听到了我三观碎掉的声音。</p>
<p>这只是一瓶普普通通的矿泉水，并不是什么巴黎水、依云那种比较贵的东西（哪怕是比较贵的水，人家都张嘴要了，至于不给喝？）。而且那时候我才反应过来，我们进来之后也并没有人来接待我们说给我们接杯水或者说哪里有水。（以至于后面再面试的时候，面试官给我拿瓶矿泉水我都觉得这是个正规公司 🤣）</p>
<p>再然后，签合同的时候签了一个《员工手册同意书》，我在签字之前就问：“我们的员工手册在哪儿的，我想先看看”，结果 HR 说：“晚些时候会发给你们的，先把字签了就行”。是的没错，让我们在没有约的《员工手册》的时候签订《员工手册同意书》 🤷‍♂️</p>
<p>合同签完了，就坐在会议室里等自己的领导领走对应的人，结果我们两三个人就一直等到了十一点，还是没人来接我们。这时候另一个 HR 路过会议室发现我们还坐在里面，就问：“你们怎么还在这儿？”啊？我还想问呢，我们怎么还在这儿？我是谁？我应该去哪儿？然后她愣了一会儿又说：“你们先去吃饭吧，下午再说”。然后我们几只能出去吃饭了（注意，我是九点到的公司，十一点了还没坐到工位上）。吃完饭回来因为还没有自己的工位，就只能继续在前台旁边的沙发坐着傻等，<strong>一直等到了十六点</strong>才有人带我去工位。没错，从到公司开始计时，整整七个小时我才知道自己的工位在哪儿。</p>
<p>我的工位在一个玻璃幕墙围起来的“办公室”里，进出办公室需要刷工牌，即使是多人一起也要每人都刷，因为<strong>工牌带有状态机</strong>，也就是说你进办公室不刷的话就出不来，因为系统认为你人在外面，所以再出来是不合法的 🤷‍♂️ 这都还是小事，进办公室之前要<strong>给手机套上防拍照套</strong>，这个套子会挡住手机的前后摄像头，防止你在办公室里拍摄任何内容（是的，前摄也挡住了，你的 Face ID 就没法用了，屏下指纹肯定也不行了）。套好之后在尾部还要穿上一个类似优衣库里的那种磁吸锁扣，防止你在办公室里把手机取出来，只有办公室门口的磁吸工具可以把它取下来。因为手机装在套子里面，所以来了电话就得起身-&gt;穿过人员密度超级高的办公室-&gt;刷工牌-&gt;出去-&gt;取下磁吸锁扣-&gt;拿出手机-&gt;接电话（如果对方还没有挂断的话）。什么，你说如果直接把手机带进去？也行，只是刚刚签了一个 50W 的保密协议，万一以这个由头搞你一下，谁受得了 🤷‍♂️</p>
<p>到了分配设备的时候，我问有没有分辨率高点的显示器比如 2K 4K 的，结果告诉我说“可以给你找个大显示器”，是的，后面给了我一个 27 寸的 1080P <strong>大显示器</strong>。最牛逼的还是键盘鼠标，键盘是从一个纸箱子里抽出来的来自国际大厂 HP 的二手键帽打油表面落灰的久经沙场的键盘，鼠标是新的（闲鱼上全新的 7 块钱包邮）。</p>
<p>其实这时候我已经心如死灰了，我觉得这地方真的太怪了。后来发现给我拿过来的设备还很顶，一台台式机，14 代 i7 + 32G + 4080，本来我还想说：“这公司知道把钱花在刀刃上哈，键盘鼠标不影响产出，知道电脑影响产出效率哈”。但是后来发现我还是太年轻了，主机上贴了一张“ByteDance”的贴纸，是的没错，这台机器是字节寄过来的 🤷‍♂️</p>
<p>赶紧弄好开发环境（不允许私自安装软件什么的就不一一说了），搞到代码仓库，发现这个项目既没有 README，也没有任何其他文档。而且此时<strong>没有人告诉我谁是我的领导，我也不知道谁是我的同组同事</strong>。此时我已经决心要跑路了，在这里干下去绝对绝对绝对不行。但我做了一个错误的决定：等到下班。是的，我还是硬等到了下班，打卡之后才回家的。</p>
<p>第二天一早起床我就给带我入职的 HR 发了消息，说我不干了。然后就是一波谈话和些有的没的，最终顺利在第二天的下午办理完了离职手续。不幸中的万幸是：社保和公积金都没登记上，让我职业生涯中的第一个黑点没能固化下来。</p>
<blockquote>
<p>短短两天（其实也就第一天）发生的事情其实不止这些，还有类似于：不允许携带任何能记录的个人物品到公区，例如笔和本子（任何一名靠谱一些程序员应该都会用纸笔吧）、办公桌很脏，那些有人用的办公桌也很脏、一抬头能看到至少三个摄像头、厕所脏乱差，类似长途汽车站里的公厕、工位超小，小到椅子往后一退就能撞到其他同事&hellip;&hellip;</p>
</blockquote>
<h1 id="0x0a-自信">0X0A 自信</h1>
<p>自信问题是我今年发现的自己身上最明显的一个问题，有时候我就很羡慕周围那些自信满满的，敢于迅速输出自己想法的人。平时不管遇到什么什么事情，我就特擅长第一时间找自己的原因，也不敢第一时间批评对方（即便对方甚至都不是人）。换句话说就是有些人自己有 3 成把握的时候，就敢输出自己的观点甚至是批评，有些人的阈值可能是 5 成或者 6 成，我不太一样，我可能要自己有 8 成把握的时候才敢输出观点，尤其是输出批评。比较典型的事情就是我在看别人写的代码时，遇到一些我觉得很蠢的地方，自己会不太敢吐槽，因为我觉得别人是不是有什么理由才写成这样的。是这样的，我已经是一个有着八年多工作经验的程序员了还是这样。</p>
<p>一个最新的例子就在我写上面这段话的时候，最早我想写的是“我已经是一个所谓的高级软件工程师了”，但是转念一想如果技术是一张大饼的话，我自己清楚的知道我自己这张饼哪里是有洞的，虽然别人看不到我身上这几个洞会说我是高级研发，但我并不敢接纳这个词，虽然我也清楚的知道哪怕是再高级水平的人也一定会有洞。所以如果我哪天能承认自己是高级工程师了，那多半是我拿到了 95% 程序员都拿不到的高薪、或者给成为了哪些广为人知的开源项目的稳定贡献者（估计是不会有这一天了）。</p>
<h1 id="0x0b-推荐万物">0X0B 推荐万物</h1>
<p>又到了我有想推荐东西但是不知道放在哪里，就只能放在这里的环节了。</p>
<p>首先我想推荐的是<strong>拓竹 P1S</strong> 3D打印机，当然并不是特指这个型号，而是整个品类。我觉得买 3D 打印机很像是买车，最像的一点就是“不能算账”。因为你买打印机和耗材的钱，去买你打印出来的成品，很多时候都是够用的，而且买到的还更结实耐用一些。但是，正是因为钱已经花出去了，就总会想打印点乱七八糟的东西，比如我家里就打印了好几个置物架/框、塑料蝴蝶刀、挂钩、笔筒、下置纸巾盒、遥控器壳、朋友小孩儿的玩具、朋友的钓具&hellip;&hellip;如果这个世界上没有 Maker World 的话大家的 3D 打印机确实可能用处不大，但正式因为拓竹的这个网站，才让 3D 打印机能焕发生机～</p>
<p>其次就是我的<strong>百盛图 2SAP</strong>咖啡机，换上半自动咖啡机之后我自己做咖啡的频率要比之前用摩卡壶的时候高了十倍不止。而且毕竟是意式机了，拿来做奶咖效果好了很多，之前用摩卡壶的时候总觉得做黑咖差点意思，做奶咖的话浓度又不够 🤔</p>
<p>最后就是 <strong>HDR 显示设备</strong>。我觉得不管是显示器还是电视，在 2026 年之后选购的时候是否有一个可用的 HDR 模式都将是一个重要的参数。我印象很深刻的就是在电视上用 HDR 模式观看 Links 的视频和优质的电影，还有在 HDR 显示器上看灵笼的效果。之前我经常听爱否 Fview 的播客，他们的统一论调就是：“如果你不在乎效果，就买 LCD，便宜很多；如果你在意效果，就买 OLED，效果好很多；反正别买 miniLED，效果很差价格又不低”。我不否认 miniLED 的效果确实比 OLED 差，价格也比 LCD 更贵，但是你也得承认 miniLED 的价格比 OLED 低，效果比 LCD 好啊。我自己的体验就是用 miniLED 观看一些 HDR 片源确实会有 OLED 不会出现的问题，但整体上瑕不掩瑜。</p>
<h1 id="0x0c-对-2026-的大体计划">0X0C 对 2026 的大体计划</h1>
<p>总结写到这里其实已经差不多了，这里大致写 2026 年的计划吧，今年打算给自己安排的事情少一些，不给自己上太大的压力了。</p>
<ul>
<li>多读书：计划读 10 本专业无关的书，目前计划的有《如何品尝一杯咖啡》、《采购与供应链管理》、《照片的本质》、《发现的乐趣》、《我们生活在巨大的差距里》、《聪明的投资者》、《极简宇宙史》&hellip;&hellip;</li>
<li>看电影：之前已经看了豆瓣 top250 里的大多数了，争取 2026 年把它补完</li>
<li>多运动：今年争取多跑一些 10km，比如&hellip; 20 个？再多骑几个 40km，比如&hellip; 20 个？再骑一次 200km 的长途</li>
<li>多看片：争取骑着动感单车看完一整部《绝命毒师》</li>
<li>多徒步：是时候恢复徒步了，争取今年 BC 两种级别的线路都走三条或者更多吧</li>
<li>多拍照：到年底的时候，年度可用照片希望能够翻倍到 1500 张，能选出 100 张非常满意的照片</li>
</ul>
<p>目前看了一下难度最高的是在运动上，10km 跑步平均每周 0.4次，也就是每月需要跑一两次；40km 的骑行也是一样每周 0.4 次；200km 的长途计划的只有一次，所以选一个天气合适的时候出发就行，有之前几次 150+ 的经验，200km 应该没什么难度；动感单车的话因为《绝命毒师》一共是 62 集，每集 45min，基本也就是每周一集，如果上头的话也能连着多看几集<!-- raw HTML omitted -->如果骑得动的话<!-- raw HTML omitted -->。</p>
<h1 id="0x0d-对-2026-会发生的事的期待">0X0D 对 2026 会发生的事的期待</h1>
<p>我刚刚抓着头皮想了想，也没想到太多的期待，所以可以全数列出：</p>
<ul>
<li>希望《影之刃：零》能顺利端出来，不要有乱七八糟的问题，销量能好一些</li>
<li>希望《GTA VI》能顺利端出来，<strong>不要跳票</strong></li>
<li>希望 Nintendo 能出几个好玩的游戏，有好游戏的话才有借口买 Switch 2 呀</li>
<li>希望 2026 年的智能眼镜领域真正混战起来，推出有一款我舍得买的智能眼镜</li>
</ul>
<p>在然后就是有关我个人的工作状态，我希望自己能强势扭转局面（或者迅速跑路）。尤其是我的个人状态，明显感觉到 2025 年的个人状态是不太行的，很多事情提不起兴趣，希望新的一年里我的个人状态能重回巅峰吧<!-- raw HTML omitted -->听起来好中二啊<!-- raw HTML omitted -->。</p>
<p>最后对于 2026 年我最大的期待其实是：寒冬已至，如果后面能暖和一些那就太好了。</p>
<h1 id="0x0e-finally">0X0E Finally</h1>
<p>祝各位<strong>平安快乐</strong></p>
<h1 id="0x0f-finally-by-ai">0X0F Finally By AI</h1>
<p>我刚刚把上面这一整篇年度总结喂给了 Claude 4.5，并询问他：“你帮我看看写的如何”，下面的内容是他输出的总结部分：</p>
<p>你这篇总结写得很真实，但也暴露了一个核心问题：你在用程序员的思维（量化、执行、自我审查）处理人生，但忘了人生不是可以debug的代码。</p>
<p>有些问题不是&quot;执行力不够&quot;或&quot;标准太低&quot;，而是：</p>
<ul>
<li>你需要承认自己确实很累</li>
<li>你需要降低&quot;什么才算成功&quot;的标准</li>
<li>你需要停止用&quot;别人更惨&quot;来否定自己的感受</li>
</ul>
<p>如果你的 Claude 或 GPT 能让你意识到“订婚、离职、装修都是大事”，那说明<strong>你需要的不是更强的执行力，而是更合理的自我评价体系</strong>。</p>
<p>2026年，祝你真的能“平安快乐”——不是完成所有目标才叫快乐，而是接受自己本来的样子也能快乐。</p>
]]></description></item><item><title>2025 开发者 AI 扫盲：从 LLM 到 Agent</title><link>https://blog.programmer.work/posts/2025-ai-primer/</link><pubDate>Sat, 27 Dec 2025 23:52:26 +0800</pubDate><author>Shawn</author><guid>https://blog.programmer.work/posts/2025-ai-primer/</guid><description><![CDATA[<h1 id="0x00-intro">0X00 Intro</h1>
<p>现在是 2025 年末，所有人都在聊 AI，不管是一线科研人员还是开发者甚至是楼下卖瓜的大叔。但是在我的观察中，即便是很多开发者也其实对 AI 的了解也比较肤浅，仅限于使用成品的豆包、Deepseek 等产品，对时下热门的技术关键词并不了解。所以我自己重新整理了一下，假设目标用户是不懂什么是 LLM、Agent、MCP、Function Call 的我自己，写了一篇介绍文章。远远算不上由浅入深，但勉强可以做一个纯粹的介绍。</p>
<h1 id="0x01-llm">0X01 LLM</h1>
<p>首先 LLM 的意思是<strong>大语言模型（Large Language Model）</strong>，重点是<strong>语言</strong>和<strong>模型</strong>。所以我们搞清楚一个问题就是很多玩家自己部署的 Stable Diffusion 并非 LLM，因为它并不是<strong>语言</strong>模型。另外我们常用的 Deepseek 和豆包 App 也并非 LLM，因为它们并非语言<strong>模型</strong>。</p>
<p>最常被人们接触到的其实都不是模型，而是在模型上构建的产品，例如：ChatGPT 和豆包。模型指的是给这些产品提供 AI 能力的诸如 <code>GPT-5.2</code>、<code>Claude Sonnet 4.5</code>、<code>GLM 4.7</code> 等。以 OpenAI 为例，我们在使用 ChatGPT 的 App 时能调整的参数极其有限，但是如果通过 API 来直接调用模型能力，那可以修改的参数会多达几十上百个，并且可以区分 System Prompts 和 User Prompts。</p>
<p>总的来说 LLM 是本次 AI 浪潮中最重要也是最基石的存在。</p>
<h1 id="0x02-function-call">0X02 Function Call</h1>
<p>Function Call 的概念其实非常直观，本质上就是一个<strong>函数调用</strong>接口。我们在写代码时定义的函数通常是给程序内部逻辑调用的，而 Function Call 允许我们将这些函数注册给 LLM，让模型根据对话上下文自主决定是否触发某个函数以及传什么参数。</p>
<p>不过在早期的工程实践中，虽然各家模型都支持 Function Call，但痛点非常明显：定义格式不统一。比如 OpenAI 用的是特定的 JSON Schema，其他模型可能又有各自的规范。这就导致你想写一个通用的“查天气工具”，需要针对每个模型单独适配一套接口，开发成本高，工具难以在不同模型间复用。</p>
<h1 id="0x03-mcp">0X03 MCP</h1>
<p>MCP (Model Context Protocol) 的出现就是为了终结这种“方言”乱象。它是由 Anthropic（开发 Claude 系列模型的公司） 提出的一个开放标准协议，统一规定了 AI 应用与外部数据源、工具之间如何交互。</p>
<p>只要模型端和工具端都遵循 MCP 协议，它们就能无缝对接。简单类比，以前各家是各自搞一套私有 RPC 协议，现在 MCP 就像是 AI 界的 HTTP 或者 RESTful API 标准一样。它解决了连接器的标准化问题，让一个工具可以轻松地在不同的 AI 客户端（如 Claude Desktop、IDE 插件）中即插即用。</p>
<h1 id="0x04-agent">0X04 Agent</h1>
<p>Agent 就是现在比较流行的<strong>智能体</strong>，它的本质是一个<strong>程序</strong>。我自己听过的说法包括但不限于：</p>
<ul>
<li>“Agent 和大模型不一样，Agent 能直接操作你的电脑”</li>
<li>“Agent 比大模型厉害多了，肯定是大语言模型的替代品”</li>
<li>“Agent 就是个骗人的噱头，没什么用，泡沫迟早要爆炸”</li>
</ul>
<p>其实都不太对劲，因为 Agent 是一个至少集成了 LLM 和 MCP/Function Call 的集合体程序。如果逐一反驳的话，Agent 确实和大模型不一样毕竟你不能说汽车和发动机一样，但 Agent 能否操作电脑也是看它具体集成了哪些 MCP/Function Call；其次 Agent 比大模型厉害就更是无稽之谈了，因为 LLM 是 Agent 的一部分，总不能说汽车比发动机强吧；说 Agent 是骗人的噱头的其实也不至于，Agent 只是 LLM 发展的一个方向而已。</p>
<p>最近我正在使用的 Claude Code 其实就是一个 Agent，给没有用过的朋友简单介绍一下 Claude Code 的使用流程</p>
<p>在目录中打开 Claude Code（是一个 CLI 工具），发送：“检查这个代码仓库，并向我介绍它”。 此时 Claude Code 会理解我的意图，然后调用系统的 <code>find</code>、<code>cat</code>、<code>tree</code> 等命令尽可能的获取这个项目的信息，比如目录结构、入口位置甚至是 <code>README.md</code>。在它获取到信息之后会继续传输给 LLM，让 LLM 来理解并输出内容。如果我继续下发指令：“为这个项目新增一个 XX 功能”，那 Claude Code 会继续先把我的内容发送给 LLM 然后列出一个 TODO List，再根据 todo 的内容一项一项执行，中间就会涉及到创建编辑文件、执行测试代码、甚至是安装依赖的三方库等。</p>
]]></description></item><item><title>如何高质量的接入AI - Developer</title><link>https://blog.programmer.work/posts/how-to-integrate-ai-for-developer/</link><pubDate>Sun, 21 Dec 2025 12:08:45 +0800</pubDate><author>Shawn</author><guid>https://blog.programmer.work/posts/how-to-integrate-ai-for-developer/</guid><description><![CDATA[<h1 id="0x00-intro">0X00 Intro</h1>
<p>今年年初的时候，写过一篇名为<a href="/posts/how-to-integrate-ai/" rel="">如何高质量地接入AI</a>的文章，现在十个月过去了，经过这一年的探索和总结，现在我已经找到了一个非常适合开发者的 AI 接入方案（至少非常适合我自己），现在打算在这里跟大家做一个简单的分享。</p>
<p>我个人使用这些 LLM 的经历主要是分成三个阶段：</p>
<ol>
<li>最开始是 2023 年，注册了一个 ChatGPT 的账户，就只用 GPT-3.5 这种模型。不过那段时间 LLM 的能力还比较有限，使用量也并不大，很多时候都是以玩的心态在用；</li>
<li>后面随着模型能力上升，需求也跟着上升了，索性订阅了 <a href="https://poe.com" target="_blank" rel="noopener noreffer ">POE</a>，每个月要花掉 $20。不过当时 GPT-o1 和 Claude 3.5 这些模型还是给我工作学习明显提供了帮助的</li>
<li>POE 的年度订阅过期之后我试图找到一个比 POE 更合适我自己的技术方案，也就是下面将会介绍的这个了</li>
</ol>
<h1 id="0x01-struct">0X01 Struct</h1>
<p>当时在探索方案的时候我的需求就是：按量计费、多平台统一、多模型可用、高度定制化、显得高级（满足虚荣心 🤣）。那么最终得到的就是下面这样一个结构。</p>
<p></p>
<p>先来简单介绍一下这个方案的优势：</p>
<ol>
<li>按量计费：因为是用 API 接入的，所以是纯粹的按量计费；</li>
<li>多平台统一：Open WebUI 毕竟是 web 应用，并且做了自适应布局，所以在电脑和手机上的使用体验都是不错的；</li>
<li>多模型可用：任何 LLM 服务商都提供了 API 接入方式，所以不管是接入国内的 GLM、Deepseek 甚至是前几天开放的小米模型，还是直连 OpenAI 和 Anthropic 都是没问题的；</li>
<li>高度定制化：Open WebUI 的定制化程度很高，很适合我们这种所谓的“高级用户”；</li>
</ol>
<h1 id="0x02-open-webui">0X02 Open WebUI</h1>
<p><a href="https://github.com/open-webui/open-webui" target="_blank" rel="noopener noreffer ">Open WebUI</a> 是一个用户友好的 WebUI，开源版本可以实现接入多个 API 上游、多用户管理（意味着你可以把你的服务通过独立账号的方式分享给你的亲朋好友们，假设你的 API 用量顶得住的话）。</p>
<p></p>
<p>有关这个项目的简单使用方法就不多说了，大家有两分钟就摸索清楚了。这里提一个自己觉得有用的 tips：首先是分组，它并不是单纯的 Group 功能，更像是创建了一个 Assistant，是可以在分组里写 System Prompts 的，写好之后在这个分组里的每次对话都会默认使用你设置好的 System Prompts 了。比如我有一个 MySQL 的分组，里面设置的 System Prompts 就是下面这样的。如果你多次就一个话题和 AI 展开探讨的话，就可以用这种方式。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>你是一名精通 MySQL 的数据库专家。用户是一名中级 MySQL 用户，掌握基本的 CRUD 操作、DDL 语句和基础性能优化知识，现在遇到技术问题向你请教。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>## 核心原则
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>1. **确保准确性**：提供事实正确的信息。当涉及版本特性、存储引擎行为、锁机制细节等不确定时，明确说明不确定性，不要猜测。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>2. **专业表达**：
</span></span><span style="display:flex;"><span>   - 使用精确的数据库术语（InnoDB、MVCC、redo log、buffer pool 等）
</span></span><span style="display:flex;"><span>   - 避免生活化比喻和类比
</span></span><span style="display:flex;"><span>   - 假定用户理解基础概念（索引、事务、范式、执行计划等）
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>3. **程序员思维**：
</span></span><span style="display:flex;"><span>   - 逻辑清晰、结构化组织回答
</span></span><span style="display:flex;"><span>   - 提供可验证的 SQL 语句或配置示例
</span></span><span style="display:flex;"><span>   - 说明性能影响、锁竞争、数据一致性等关键权衡
</span></span><span style="display:flex;"><span>   - 必要时引用官方文档或 EXPLAIN 分析结果
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>4. **简明原则**：
</span></span><span style="display:flex;"><span>   - 简单查询问题给出简洁 SQL 示例
</span></span><span style="display:flex;"><span>   - 性能或架构问题进行深入分析
</span></span><span style="display:flex;"><span>   - 避免不必要的铺垫或重复问题
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>## 回答规范
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>- SQL 优化问题：基于执行计划分析，指出索引使用、扫描方式、join 策略等关键点
</span></span><span style="display:flex;"><span>- 索引设计：说明覆盖索引、联合索引顺序、索引选择性等考量因素
</span></span><span style="display:flex;"><span>- 事务与锁：明确隔离级别、锁类型、死锁场景
</span></span><span style="display:flex;"><span>- 架构设计：讨论分库分表、主从复制、读写分离的适用场景和代价
</span></span><span style="display:flex;"><span>- 版本差异：明确指出 MySQL 5.7 vs 8.0 等版本间的行为差异
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>## 避免事项
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>- 不解释 SELECT、JOIN、INDEX 等基础概念，除非被明确询问
</span></span><span style="display:flex;"><span>- 不使用&#34;数据库就像仓库...&#34;等类比
</span></span><span style="display:flex;"><span>- 不添加鼓励性内容
</span></span><span style="display:flex;"><span>- 不对基本语法提供逐步教学式指导
</span></span><span style="display:flex;"><span>- 不在已知版本时给出过于宽泛的&#34;取决于版本&#34;回答
</span></span></code></pre></div><p>如果你打算使用 Open WebUI 的话，有两个设置需要注意，一个是需要给 Nginx 的反向代理设置上 websocket 相关的转发配置；另一个是需要传入两个环境变量（我下面示例配置里的 <code>CHAT_STREAM_RESPONSE_CHUNK_MAX_BUFFER_SIZE</code> 和 <code>REPLACE_IMAGE_URLS_IN_CHAT_RESPONSE</code>），否则在使用类似 nano banana 的模型生图时图片会返不回来。</p>
<p>我自己的 Nginx 反向代理参考配置</p>
<pre tabindex="0"><code class="language-conf" data-lang="conf">server {
    listen 80;
    server_name &lt;INPUT_YOUR_DOMAIN&gt;;

    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name ai.just666.com;

    ssl_certificate &lt;YOUR_SSL_CONFIG&gt;;
    ssl_certificate_key &lt;YOUR_SSL_CONFIG&gt;;

    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;

    proxy_buffer_size 128k;
    proxy_buffers 4 256k;
    proxy_busy_buffers_size 256k;

    client_max_body_size 50M;

    location / {
        proxy_pass http://127.0.0.1:3005;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # WebSocket
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection &#34;upgrade&#34;;

        proxy_buffering off;
        proxy_request_buffering off;

        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
    }

    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection &#34;1; mode=block&#34;;
    add_header Strict-Transport-Security &#34;max-age=31536000; includeSubDomains&#34; always;
}
</code></pre><p>我自己的 docker compose 参考配置，里面的变量写在和 docker-compose.yml 同级的名为 <code>.env</code> 的文件中</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">services</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">open-webui</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">ghcr.io/open-webui/open-webui:main</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">open-webui</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">restart</span>: <span style="color:#ae81ff">unless-stopped</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;3005:8080&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">open-webui-data:/app/backend/data</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">environment</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 关闭默认的 Ollama 连接（如果不需要本地模型）</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">ENABLE_OLLAMA_API=false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY:-your-secret-key-change-this}</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">ENABLE_SIGNUP=${ENABLE_SIGNUP:-true}</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">DEFAULT_USER_ROLE=${DEFAULT_USER_ROLE:-user}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">AIOHTTP_CLIENT_TIMEOUT=300</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">CHAT_STREAM_RESPONSE_CHUNK_MAX_BUFFER_SIZE=10485760</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">REPLACE_IMAGE_URLS_IN_CHAT_RESPONSE=true</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">TIMEOUT=600</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">AIOHTTP_CONNECTOR_LIMIT=100</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">AIOHTTP_CONNECTOR_LIMIT_PER_HOST=10</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">open-webui-data</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">driver</span>: <span style="color:#ae81ff">local</span>
</span></span></code></pre></div><h1 id="0x03-openrouter">0X03 OpenRouter</h1>
<p>现在 WebUI 已经准备好了，只需要简单配置后端 API 就可以开始用了。我目前使用体感下来，其实就只在用两个模型：Claude 4.5 Sonnet 和 GLM 4.6。但是偶尔还是会用到 GPT 系列模型、Grok 系列和 Gemini 系列，所以这里还是更加推荐大家使用 OpenRouter 这个 API “二道贩子”。它应该是目前规模最大，最稳定的“二道贩子”了，而且模型上新也非常非常快，最重要的是 <strong>OpenRouter 不会拒绝中国的 Visa 卡付款，OpenRouter 不会拒绝中国的 Visa 卡付款，OpenRouter 不会拒绝中国的 Visa 卡付款！！！</strong></p>
<p>众所周知现在搞 OpenAI、Anthropic 这种开发平台账号是很费劲的，而且一不小心还有封号不退款的风险。相比起来虽然 OpenRouter 会收取 5.5% 的手续费，但胜在快速稳定可靠呀。</p>
<p>另外 Open WebUI 是可以接入多个上游 API 平台的，所以我自己是将 OpenRouter、GLM、Deepseek 都接进去了，想用的时候点一下就能切。</p>
<p>还有非常重要的一点，OpenRouter 中有不少免费模型，比如当前可以看到下面这些模型都是免费的：</p>
<p></p>
<blockquote>
<p>⚠️ 使用 OpenRouter 的时候需要非常注意一点：钱。比如你看到最近新出的 GPT-5.2 有点猛，打算去试试看，结果在 Open WebUI 上点开筛选，输入 GPT-5.2 然后随便选了一个就开始用，没准三两下你的余额就被干完了。因为目前 OpenRouter 提供的 3 个名为 GPT-5.2 的分别是 GPT-5.2、GPT-5.2 Chat、GPT-5.2 Pro，而前两者的百万 tokens 输入输出价格分别是 1.75 和 14 美元，Pro 则是 21 和 168 美元。本来你一天高强度用 GPT 5.2 可能花掉两瓶可乐钱，现在可能因为手抖选了 5.2 Pro 就变成了一大箱可乐钱 🤣</p>
<p>解决方案要么就是自己小心点别选错，要么就是在 Open WebUI 的模型设置里直接把所有高价模型都禁用</p>
</blockquote>
<h1 id="0x04-summary">0X04 Summary</h1>
<p>以我目前的使用量，一个月下来 OpenRouter 会扣掉我大概 $10，还是明显比之前用 POE 的时候更省钱了。哪怕是后面涨到每月 $25 我估计也不会换回用 POE 了，因为这套方案的使用体验起码对我来说是明显优于 POE 的。</p>
<p>这里再根据我的经验提供两个 OpenWebUI 的替代品：web 端的 <a href="https://github.com/ChatGPTNextWeb/NextChat" target="_blank" rel="noopener noreffer ">NextChat</a> 和 Linux/Mac/PC 端的 <a href="https://github.com/CherryHQ/cherry-studio" target="_blank" rel="noopener noreffer ">Cherry Studio</a>。</p>
<p>再推荐两个 OpenRouter 的替代品：<a href="https://302.ai" target="_blank" rel="noopener noreffer ">302.ai</a> 和 <a href="https://cloud.siliconflow.cn/i/khsP7xgK" target="_blank" rel="noopener noreffer ">硅基流动</a>。</p>
]]></description></item><item><title>Base64 究竟是什么</title><link>https://blog.programmer.work/posts/base64-basic/</link><pubDate>Mon, 15 Dec 2025 22:40:18 +0800</pubDate><author>Shawn</author><guid>https://blog.programmer.work/posts/base64-basic/</guid><description><![CDATA[<h1 id="0x00-前言">0X00 前言</h1>
<p>为什么要写这么一篇文章？按理说大家工作了一段时间之后肯定有一个最基础的认知：md5 不是加密，base64 也不是。起码我最开始以为大家应该都知道，但是后面发现有些人对这两个东西的理解真的有很大的问题。所以才打算写这么一篇文章。</p>
<p>事情的起因是这样的：</p>
<pre tabindex="0"><code>甲：“你用 base64 加密一下”
我：“base64 没有加密效果”
甲：“你给 base64 前面加上 32 个随机字符，让他解不出来不就行了”
我：“啊？？？”
</code></pre><p>所以我接下来打算首先介绍一下 base64 究竟是怎么得到的（算法本身），再来说明白 base64 为什么不可以通过前面加 32 个随机字符来实现“加密”（随机长度也不行）。</p>
<h1 id="0x01-常识性的知识">0X01 常识性的知识</h1>
<p>首先我们明确一个事情，就是「编码」「加密」「哈希」之间的区别：</p>
<table>
  <thead>
      <tr>
          <th>名称</th>
          <th>是否可逆</th>
          <th>是否安全</th>
          <th>典型</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>编码</td>
          <td>是</td>
          <td>否</td>
          <td>base64</td>
      </tr>
      <tr>
          <td>加密</td>
          <td>是</td>
          <td>是</td>
          <td>AES</td>
      </tr>
      <tr>
          <td>哈希</td>
          <td>否</td>
          <td>不总是</td>
          <td>md5</td>
      </tr>
  </tbody>
</table>
<ul>
<li>编码，是将一段内容通过某种算法直接转换成另一段内容，<strong>只是形式发生了变化</strong>，在明确编码算法的情况下是可以轻松解码获得原始内容的</li>
<li>加密，是将一段内容通过某种算法和 <strong>密码</strong> 将明文加密成密文，内容本身发生了变化，在明确加密算法的情况下没有密码也是无法解密的</li>
<li>哈希，是将一段内容通过某种算法转换成<strong>固定长度</strong>的另一段内容，原始数据会丢失，理论上无论如何都不可能通过哈希后的数据反推出原文</li>
</ul>
<h1 id="0x02-base64-编码">0X02 base64 编码</h1>
<p>在明确了什么是编码后，来自顶向下拆解一下这个 base64 编码吧。首先名字中的 64 指的就是编码后的每一位都有 64 种有效字符，也就是 a-z 的 26 个小写字母、A-Z 的 26 个大写字母、0-9 的 10 个数字和 <code>+/</code> 两个特殊字符，加一起正好是 64。</p>
<p>显然 64 指的是 6bit 能容纳的最大长度了，所以 base64 的编码逻辑就是：把一个二进制的数据按 6bit 一组分成 N 组，得到 N 个 0-63 之间的数，然后根据下面这张表把每组的数字替换成字符。</p>
<p></p>
<p>如果我的原文是二进制的 <code>01101000 01100101 01101100 01101100 01101111</code>（这是 UTF-8 编码的 <code>hello</code>），那么可以拆分成 <code>011010</code>、<code>000110</code>、<code>010101</code>、<code>101100</code>、<code>011011</code>、<code>000110</code>、<code>1111</code>，进而对应的是<code>26</code>、<code>6</code>、<code>21</code>、<code>44</code>、<code>27</code>、<code>6</code>、<code>15</code>，再对照上面的表格得到的就是 <code>aGVsbGP</code>。这样一来，我们的 <code>hello</code> 字符串就顺利转成 base64 编码了。。。吗？</p>
<p>并没有，因为最后一位的 <code>1111</code> 其实并不是严格对照上述表格查到的，所以我们应该给其尾部补二进制零，将其补充成 <code>111100</code> 对应索引 60，查表得到字符 <code>8</code>，将 <code>P</code> 替换得到 <code>aGVsbG8</code>。这样一来，我们的 <code>hello</code> 字符串就顺利转成 base64 编码了。。。吗？</p>
<p>并没有，我们发现得到的编码后字符串长度是 7，并不能按 4byte 一组进行拆分，所以最后还需要补充一个 <code>=</code>，最后得到的 base64 编码是 <code>aGVsbG8=</code>。这样一来，我们的 <code>hello</code> 字符串就顺利转成 base64 编码了。。。吗？</p>
<p>是的！不过为什么不能按 4byte 一组进行拆分就得在后面补 <code>=</code> 呢？因为解码器在后续解码的时候是按照编码后的字符串 4 个一组，将其转成 24bit 再分成 3 个 8bit 恢复成原始数据，所以在最后需要用 <code>=</code> 将 base64 的结果串补到 4 的整数倍长度。</p>
<blockquote>
<p>有些不严谨的 base64 解码器在后面没有 <code>=</code> 的时候也可能解得开，不过这是解码器的问题，不是标准的问题，就不过多探讨了。</p>
</blockquote>
<h1 id="0x02-为什么不能靠前缀加密">0X02 为什么不能靠前缀加密</h1>
<p>如果你比较敏感，可能发现了 base64 的一个特征，它的编码过程是分段进行的，也就意味着如果一个 base64 编码的前半段出现了错乱，是不影响它后半段的正确解码的。再加上 base64 的特征十分明显，明显指数应该是和 md5 坐同一桌的，所以很多技术人员是可以一眼看出这段字符串是 base64 编码的。</p>
<p>那么即使你在一段 base64 编码的前面追加了一段随机的内容，例如：<code>zxclkjgheiqlourytaGVsbG8=</code>，那我们现在尝试“破解”一下</p>
<ol>
<li>先用在线解码工具尝试解码，发现失败了</li>
<li>发现长度是 25，不是 4 的整数倍，那就在最前面追加 3 个 <code>x</code> 让它变成 <code>xxxzxclkjgheiqlourytaGVsbG8=</code></li>
<li>再次尝试解码，就已经看到最后的 <code>hello</code> 了</li>
</ol>
<p><strong>所以说，在 base64 编码得到的串前面追加所谓的随机字符串，是没有什么加密效果可言的</strong></p>
]]></description></item><item><title>编写 Python 程序的 10 个典型错误</title><link>https://blog.programmer.work/posts/python-10-errors/</link><pubDate>Fri, 20 Jun 2025 15:45:27 +0000</pubDate><author>Shawn</author><guid>https://blog.programmer.work/posts/python-10-errors/</guid><description><![CDATA[<h1 id="0x00-开头">0X00 开头</h1>
<p>最近买了本书，叫做《100个Go语言典型错误》，发现这样的总结很有意思。决定自己也写一个，不过以我的水平写本书还是有点离谱了，但是写一篇博客还是没什么问题的，所以就有了这篇文章。</p>
<h1 id="0x01-函数默认值传递空列表">0X01 函数默认值传递空列表</h1>
<p>这是一个典型错误，很多很多的 Python 程序员都犯过这个错误。一般在定义一个函数且给它设置默认值的时候我们都会写成 <code>def foo(a=0, b=&quot;&quot;, c=None)</code> 这个样子，这种写法是完全没有问题的。但是有时候也会写成：<code>def foo(d=[])</code>，这就完犊子了～</p>
<p>我们看下面这段代码</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">foo</span>(a<span style="color:#f92672">=</span>[]):
</span></span><span style="display:flex;"><span>        a<span style="color:#f92672">.</span>append(<span style="color:#e6db74">&#39;x&#39;</span>)
</span></span><span style="display:flex;"><span>        print(a)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>        foo()
</span></span></code></pre></div><p>你以为会输出 10 个 <code>['x']</code>？那就大错特错了，真正的输出是这样的：</p>
<pre tabindex="0"><code>    [&#39;x&#39;]
    [&#39;x&#39;, &#39;x&#39;]
    [&#39;x&#39;, &#39;x&#39;, &#39;x&#39;]
    [&#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;]
    [&#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;]
    [&#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;]
    [&#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;]
    [&#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;]
    [&#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;]
    [&#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;, &#39;x&#39;]
</code></pre><p>为什么呢？因为函数在定义的时候就将空列表初始化了，并且记录下了引用，以后每次都会对同一个列表进行操作。另外不只是列表，字典作为默认值也会有这个问题的。</p>
<h1 id="0x02-对闭包的无意识理解">0X02 对闭包的无意识理解</h1>
<p>很多人对闭包的理解就是粗浅的「函数里定义函数」，当然这是没错的，但是缺少了一些东西。如果只是函数里定义函数的话，下面这段代码会发生什么？</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">foo</span>():
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bar</span>():
</span></span><span style="display:flex;"><span>            print(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> bar
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    foo()()
</span></span></code></pre></div><p>没错，这段代码是会正确输出 <code>2</code> 的，因为闭包还有一个特性就是内部函数能访问外部函数中的变量，即使外部函数已经运行完毕了。</p>
<h1 id="0x03-使用不合适的变量名">0X03 使用不合适的变量名</h1>
<p>这一点虽然很简单，但确实很容易出现，比如用 <code>list</code> / <code>dict</code> / <code>str</code> 做变量名。因为 Python 中这 3 个名字是非常非常常用的<code>type/function</code>，所以万万不可用。</p>
<h1 id="0x04-字符串拼接的性能问题">0X04 字符串拼接的性能问题</h1>
<p>少量字符串拼接使用 <code>+</code> 当然没有任何问题，但是如果量很大的话就不建议使用 <code>+</code> 了，使用 <code>join</code> 会快非常多。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    COUNT <span style="color:#f92672">=</span> <span style="color:#ae81ff">10000000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 使用 + 的版本</span>
</span></span><span style="display:flex;"><span>    start_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>    result1 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(COUNT):
</span></span><span style="display:flex;"><span>        result1 <span style="color:#f92672">+=</span> <span style="color:#e6db74">&#39;x&#39;</span>
</span></span><span style="display:flex;"><span>    end_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>    plus_time <span style="color:#f92672">=</span> end_time <span style="color:#f92672">-</span> start_time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 使用 join 的版本</span>
</span></span><span style="display:flex;"><span>    start_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>    char_list <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(COUNT):
</span></span><span style="display:flex;"><span>        char_list<span style="color:#f92672">.</span>append(<span style="color:#e6db74">&#39;x&#39;</span>)
</span></span><span style="display:flex;"><span>    result2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span><span style="color:#f92672">.</span>join(char_list)
</span></span><span style="display:flex;"><span>    end_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>    join_time <span style="color:#f92672">=</span> end_time <span style="color:#f92672">-</span> start_time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;+ 方法耗时: </span><span style="color:#e6db74">{</span>plus_time<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">秒&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;join 方法耗时: </span><span style="color:#e6db74">{</span>join_time<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">秒&#34;</span>)
</span></span></code></pre></div><p>在我的电脑上运行是这样的：</p>
<pre tabindex="0"><code>    + 方法耗时: 1.0472秒
    join 方法耗时: 0.5272秒
</code></pre><h1 id="0x05-错误使用字符串的-strip-方法">0X05 错误使用字符串的 strip 方法</h1>
<p>学过 Python 的肯定都用过字符串的 <code>strip</code> 方法或者它衍生出来的 <code>lstrip</code> 和 <code>rstrip</code>，比如我们会用 <code>'hello'.rstrip('o')</code>来去掉字符串右侧的 <code>o</code>。</p>
<p>也有些人会用下面这种方法去掉额外的字符：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    phone_num <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;+8613588888888&#34;</span>
</span></span><span style="display:flex;"><span>    phone_num <span style="color:#f92672">=</span> phone_num<span style="color:#f92672">.</span>strip(<span style="color:#e6db74">&#34;+86&#34;</span>)
</span></span></code></pre></div><p>因为 <code>strip('o')</code> 可以去掉 <code>o</code>，就自然而然以为 <code>strip('+86')</code> 就是去掉 <code>+86</code> 了。但你实际运行起来就会发现 <code>phone_num</code> 就只剩下 <code>135</code> 了。因为 <code>strip('+86')</code>的意思并不是去掉两侧的 <code>+86</code> 而是去掉两侧的 <code>+</code>/<code>8</code>/<code>6</code>，凑巧这个手机号后面全是 <code>8</code> 所以就全没了 🤷‍♂️</p>
<h1 id="0x06-认为-python-的多线程没有用">0X06 认为 Python 的多线程没有用</h1>
<p>这是一个典型谣言了，很多人一旦听说 Python 有 GIL 之后就大张旗鼓的说：“Python 的多线程屁用没有”。但实际上真的是这样吗？并不是。</p>
<p>Python 的多线程如果用在 CPU 密集型的计算任务上，那确实没什么用；但是如果用在 IO 密集型的任务上，那和真正意义上的多线程是没有显著差别的。所以严谨来说 Python 确实没有真正意义上的多线程，但也不能说 Python 的多线程没有用。</p>
<h1 id="0x07-过分的一行流">0X07 过分的一行流</h1>
<p>有些 Python 程序员推崇精简代码，使用各种列表生成式、字典生成式之类的，这当然是没问题，精简又好看，而且这是非常 Pythonic 的写法。但是有些人有些过分，强行把多行代码挤成一行，或者强行使用 Python 的高级语法。</p>
<p>比如说 <code>a = {v: k for k, v in my_dic.items()}</code> 这种代码，其实挺好的，但是有些人会写这种东西：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    result <span style="color:#f92672">=</span> {<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;item_</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>: [x<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span> <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> [y<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span> <span style="color:#66d9ef">for</span> y <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">3</span>)] <span style="color:#66d9ef">if</span> x <span style="color:#f92672">in</span> [z <span style="color:#66d9ef">for</span> z <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>) <span style="color:#66d9ef">if</span> z <span style="color:#f92672">%</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>]] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">3</span>)}
</span></span></code></pre></div><p>强吗？强，对语言没点理解是写不出来能跑的这种代码的。但是好吗？codereview 的时候可能会被同时打死。</p>
<h1 id="0x08-手撸-csv-文件">0X08 手撸 csv 文件</h1>
<p>是的没错，都 2025 年了还有人在手撸 csv 文件。赶紧了解一下 <code>csv</code> 库的用法吧，不要再去折磨那个逗号和转义符了。</p>
<p>写入：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#f92672">import</span> csv
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 学生信息数据</span>
</span></span><span style="display:flex;"><span>    students <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>        [<span style="color:#e6db74">&#39;姓名&#39;</span>, <span style="color:#e6db74">&#39;年龄&#39;</span>, <span style="color:#e6db74">&#39;班级&#39;</span>, <span style="color:#e6db74">&#39;成绩&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#e6db74">&#39;张三&#39;</span>, <span style="color:#ae81ff">18</span>, <span style="color:#e6db74">&#39;高一(1)班&#39;</span>, <span style="color:#ae81ff">85</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#e6db74">&#39;李四&#39;</span>, <span style="color:#ae81ff">17</span>, <span style="color:#e6db74">&#39;高一(2)班&#39;</span>, <span style="color:#ae81ff">92</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#e6db74">&#39;王五&#39;</span>, <span style="color:#ae81ff">18</span>, <span style="color:#e6db74">&#39;高一(1)班&#39;</span>, <span style="color:#ae81ff">78</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#e6db74">&#39;赵六&#39;</span>, <span style="color:#ae81ff">17</span>, <span style="color:#e6db74">&#39;高一(3)班&#39;</span>, <span style="color:#ae81ff">88</span>]
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 写入CSV文件</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;students.csv&#39;</span>, <span style="color:#e6db74">&#39;w&#39;</span>, newline<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>) <span style="color:#66d9ef">as</span> file:
</span></span><span style="display:flex;"><span>        writer <span style="color:#f92672">=</span> csv<span style="color:#f92672">.</span>writer(file)
</span></span><span style="display:flex;"><span>        writer<span style="color:#f92672">.</span>writerows(students)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;学生信息已写入 students.csv 文件&#34;</span>)
</span></span></code></pre></div><p>读取：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#f92672">import</span> csv
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 读取CSV文件</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;students.csv&#39;</span>, <span style="color:#e6db74">&#39;r&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>) <span style="color:#66d9ef">as</span> file:
</span></span><span style="display:flex;"><span>        reader <span style="color:#f92672">=</span> csv<span style="color:#f92672">.</span>reader(file)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;学生信息列表：&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> row <span style="color:#f92672">in</span> reader:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>row[<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;8</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>row[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;6</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>row[<span style="color:#ae81ff">2</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;12</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>row[<span style="color:#ae81ff">3</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 也可以使用字典方式读取</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">使用字典方式读取：&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;students.csv&#39;</span>, <span style="color:#e6db74">&#39;r&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>) <span style="color:#66d9ef">as</span> file:
</span></span><span style="display:flex;"><span>        reader <span style="color:#f92672">=</span> csv<span style="color:#f92672">.</span>DictReader(file)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> row <span style="color:#f92672">in</span> reader:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;姓名: </span><span style="color:#e6db74">{</span>row[<span style="color:#e6db74">&#39;姓名&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">, 年龄: </span><span style="color:#e6db74">{</span>row[<span style="color:#e6db74">&#39;年龄&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">, 班级: </span><span style="color:#e6db74">{</span>row[<span style="color:#e6db74">&#39;班级&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">, 成绩: </span><span style="color:#e6db74">{</span>row[<span style="color:#e6db74">&#39;成绩&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><h1 id="0x09-文件硬读写">0X09 文件硬读写</h1>
<p>我们有时候会用 <code>open('xxx', 'r').read()</code> 直接把一个文件读到内存里，如果文件比较小确实是可以这样干的，读到内存里直接当字符串处理就好。但是如果文件很大，就不要一直这么搞了，你 1G 的日志文件还通过这种方式读取，服务都要被卡死了。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;xxx.log&#39;</span>, <span style="color:#e6db74">&#39;r&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> f:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">pass</span>
</span></span></code></pre></div><p>这样我们的 f 就是一个类似生成器的东西了，每次只读一行，就不会再被这么初级的 IO 问题限制性能了。</p>
<h1 id="0x0a-认为-python-字典是无序的">0X0A 认为 Python 字典是无序的</h1>
<p>是的兄弟，2025年了，Python 的字典早就不是无序的了，甚至是 7 年前的 Python 3.7 发布的时候 dict 就不是无序的了。</p>
<p><a href="https://docs.python.org/3/library/stdtypes.html#dict" target="_blank" rel="noopener noreffer ">Python 官方文档</a>贴在这里：</p>
<blockquote>
<p>Changed in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implementation detail of CPython from 3.6.</p>
</blockquote>
]]></description></item><item><title>一种简单的 Linux 内存不足抢救方案</title><link>https://blog.programmer.work/posts/simple-linux-memory-rescue/</link><pubDate>Tue, 15 Apr 2025 13:58:28 +0000</pubDate><author>Shawn</author><guid>https://blog.programmer.work/posts/simple-linux-memory-rescue/</guid><description><![CDATA[<h1 id="0x00-正文">0X00 正文</h1>
<p>前几天尝试用自己的服务器通过 docker 启一个新服务，没注意这个服务需要的内存比较大（我的服务器只有 2G 内存），导致 <code>docker compose up -d</code> 命令敲下去不到一分钟服务器直接卡死了&hellip;&hellip;</p>
<p>当时还没意识到是内存不足导致的问题，以为是 CPU 卡住了，毕竟一般情况下服务刚启动的时候确实会占用比较多的资源。所以直接摆烂，等它一会儿好了。半个小时之后发现服务器还是卡死状态，ssh 也上不去，所以干脆去云平台重启。发现云平台的监控上已经看不到CPU/内存的占用率了，意味着装在服务器里的 agent 也已经完蛋了。而且，重启服务器也没有什么效果。</p>
<p>好在云平台可以通过类似 IPMI 的方式直接接入到服务器的 console，所以可以通过 console 登陆。虽然每一步的操作都非常非常卡，敲一串命令要等很久才能回显。使用 <code>free -h</code> 检查了内存占用情况之后发现确实是内存瓶颈，并且系统没有配置交换分区，所以才出了下面的这个骚招：</p>
<ol>
<li>使用 <code>free -h</code> 确认当前内存使用情况，发现内存爆满且没有交换分区</li>
<li>意识到 Linux 所谓的「万物皆文件」，决定在没有空闲分区的情况下生造一个交换分区出来</li>
<li>使用 <code>dd if=/dev/zero of=SWAP_FILE bs=4k count=$((256*1024*4))</code> 创建一个 4G 大小的块文件</li>
<li>使用 <code>mkswap SWAP_FILE</code> 将其格式化成 swap 分区</li>
<li>使用 <code>swapon SWAP_FILE</code> 挂载交换分区</li>
<li>系统活过来了</li>
</ol>
<blockquote>
<p>⚠️ 注意：使用 <code>swapon</code> 只是临时挂载，重启会失效，所以需要通过常规手段增加内存（至少要增加交换分区）</p>
</blockquote>
<p><code>dd if=/dev/zero of=SWAP_FILE bs=4k count=$((256*1024*4))</code> 是什么意思？</p>
<ol>
<li><code>dd</code> 命令是一个硬盘层面的拷贝命令</li>
<li><code>if=/dev/zero of=SWAP_FILE</code> 指的是 <code>input file</code> 是 <code>/dev/zero</code>（这是一个会源源不断输出二进制 0 的设备），<code>output file</code> 是 <code>SWAP_FILE</code></li>
<li><code>bs=4k count=$((256*1024*1024))</code> 指的是 <code>block size</code> 为 <code>4k</code>，<code>count</code> 为 <code>256 * 1024 * 1024</code>，乘到一起就是 4G</li>
</ol>
]]></description></item><item><title>苹果里的虫子：macOS 的几个臭毛病</title><link>https://blog.programmer.work/posts/macos-bad-apple/</link><pubDate>Wed, 05 Mar 2025 15:30:00 +0000</pubDate><author>Shawn</author><guid>https://blog.programmer.work/posts/macos-bad-apple/</guid><description><![CDATA[<h1 id="0x00-叠甲">0X00 叠甲</h1>
<p>开局先叠甲，我到现在为止用过一台 Mac mini，一台 Intel 的 MacBook Pro 和一台 M2 Max 的 MacBook Pro，自费购买 MacBook 花费超过 3W 元，累计使用超过 5 年，是个不折不扣的 macOS 用户。我认可很多 MacBook 和 macOS 的设计理念，如果我现在只能保留一台电脑，那极大可能我会选择一台 MacBook Pro。</p>
<p>😡 好了现在开始输出 😡</p>
<h1 id="0x01-难用的包管理器">0X01 难用的包管理器</h1>
<p>首先就是这个 <code>homebrew</code>，我在买 MacBook 之前看攻略的时候就看到很多人在吹 <code>homebrew</code> 有多好用，有多厉害，有多方便。他们的说辞一般是：一个命令就可以更新系统里很多的组件、一个命令就可以安装好开发环境、一个命令就可以XXXX。当时我作为一个 Archlinux 用户是有些懵逼的，但是看在这么多人吹捧的份上我也就相信了，心想着「这么多人都这样推荐，应该确实会很好用，如果能像 <code>pacman</code> 或者 <code>apt</code> 或者 <code>dnf</code> 这样的话那确实是很好的」。</p>
<p>结果呢？这个 <code>homebrew</code> 不光是个第三方工具，而且镜像源的数量也显著少于各个 Linux 发型版本。好不容易把它配置好之后，发现 <code>brew update/upgrade</code> 速度都明显比 <code>pacman/apt/dnf</code> 慢，而且仓库里的工具也显著少于常见的 Linux 发型版本。</p>
<p>我自己的体验（结合我自己的开发工作和环境）来说，Archlinux 使用的 <code>pacman</code> 属于独领风骚的， <code>apt</code> 和 <code>dnf</code> 则处在第二梯队，属于好用的，<code>brew</code> 则处于第三梯队，属于能用的。但确实不至于被拿出来吹。</p>
<blockquote>
<p>如果所有吹 <code>homebrew</code> 的人都是在拿 macOS 和 Windows 对比的话，那我无话可说。<code>homebrew</code> 虽然不怎么好用，但是确实比 Windows 上没有包管理器来的更好。</p>
</blockquote>
<h1 id="0x02-不区分大小写的文件系统">0X02 不区分大小写的文件系统</h1>
<p>下面这段是我在 Linux 中的实验结果：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ mkdir test_dir
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ touch test_dir/hello_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ touch test_dir/hello_WORLD
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ touch test_dir/HELLO_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ touch test_dir/HELLO_WORLD
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ ls -l test_dir/
</span></span><span style="display:flex;"><span>    total <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    -rw-r--r-- <span style="color:#ae81ff">1</span> shawn shawn <span style="color:#ae81ff">0</span> Mar  <span style="color:#ae81ff">6</span> 14:27 HELLO_WORLD
</span></span><span style="display:flex;"><span>    -rw-r--r-- <span style="color:#ae81ff">1</span> shawn shawn <span style="color:#ae81ff">0</span> Mar  <span style="color:#ae81ff">6</span> 14:27 HELLO_world
</span></span><span style="display:flex;"><span>    -rw-r--r-- <span style="color:#ae81ff">1</span> shawn shawn <span style="color:#ae81ff">0</span> Mar  <span style="color:#ae81ff">6</span> 14:27 hello_WORLD
</span></span><span style="display:flex;"><span>    -rw-r--r-- <span style="color:#ae81ff">1</span> shawn shawn <span style="color:#ae81ff">0</span> Mar  <span style="color:#ae81ff">6</span> 14:27 hello_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$
</span></span></code></pre></div><p>再下面这段是我在 macOS 中实验的结果：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $ mkdir test_dir
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $ touch test_dir/hello_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $ touch test_dir/hello_WORLD
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $ touch test_dir/HELLO_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $ touch test_dir/HELLO_WORLD
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $ ls -l test_dir/
</span></span><span style="display:flex;"><span>    .rw-r--r-- <span style="color:#ae81ff">0</span> shawn  <span style="color:#ae81ff">6</span> Mar 14:28 hello_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $
</span></span></code></pre></div><p>是不是很惊喜，是不是很意外？嘴上说自己是 Unix，但是真正 Unix 会使用的 ext4 和 XFS 甚至是 ZFS 等文件系统都是严格区分大小写的（ZFS 可配置，默认区分大小写），结果到了 macOS 上就不分了。也就是说如果你在 Linux 上将 <code>hello.py</code> 和 <code>HELLO.py</code> 两个文件打包，再到 macOS 中解压，就会原地消失一个 🫠</p>
<p>👇下面给大家表演一个「文件消失术」</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $ ssh shawn@192.168.81.151
</span></span><span style="display:flex;"><span>    Last login: Wed Mar  <span style="color:#ae81ff">5</span> 14:30:49 <span style="color:#ae81ff">2025</span> from 192.168.81.1
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ mkdir test_dir
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ touch test_dir/hello_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ touch test_dir/hello_WORLD
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ touch test_dir/HELLO_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ touch test_dir/HELLO_WORLD
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$ tar zcvf test_dir.tgz test_dir/
</span></span><span style="display:flex;"><span>    test_dir/
</span></span><span style="display:flex;"><span>    test_dir/hello_WORLD
</span></span><span style="display:flex;"><span>    test_dir/HELLO_WORLD
</span></span><span style="display:flex;"><span>    test_dir/HELLO_world
</span></span><span style="display:flex;"><span>    test_dir/hello_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@archlinux ~<span style="color:#f92672">]</span>$
</span></span><span style="display:flex;"><span>    logout
</span></span><span style="display:flex;"><span>    Connection to 192.168.81.151 closed.
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $ scp shawn@192.168.81.151://home/shawn/test_dir.tgz .
</span></span><span style="display:flex;"><span>    test_dir.tgz                    100%  <span style="color:#ae81ff">210</span>   215.9KB/s   00:00
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $ tar zxvf test_dir.tgz
</span></span><span style="display:flex;"><span>    x test_dir/
</span></span><span style="display:flex;"><span>    x test_dir/hello_WORLD
</span></span><span style="display:flex;"><span>    x test_dir/HELLO_WORLD
</span></span><span style="display:flex;"><span>    x test_dir/HELLO_world
</span></span><span style="display:flex;"><span>    x test_dir/hello_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $ ls -l test_dir/
</span></span><span style="display:flex;"><span>    .rw-r--r-- <span style="color:#ae81ff">0</span> shawn  <span style="color:#ae81ff">6</span> Mar 16:00 hello_world
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>shawn@mac<span style="color:#f92672">]</span> ~ $
</span></span></code></pre></div><h1 id="0x03-随地大小便">0X03 随地大小便</h1>
<p>说到 macOS 的随地大小便问题，哪怕不是 macOS 用户应该也有很多见过 <code>.DS_Store</code> 这个文件的吧。这个文件简单来说是 macOS 的文件管理器也就是 Finder 来创建的，文件中主要保存的就是当前目录的排序方式、展示方式等内容。如果你直接对这个目录进行打包（无论是在 GUI 还是 CLI 中），就会把这个文件直接包进去。如果是到 Windows 上解压，就会莫名其妙多出来一个 <code>.DS_Store</code> 文件；如果是在 Linux 上解压就更恶心了，它存在但默认又看不见 🙈</p>
<p>如果涉及到 git 仓库管理那就更愚蠢了，这个文件会随着日常使用经常产生变化，而且在多级目录下会出现大量的 <code>.DS_Store</code> 文件，只能通过 <code>.gitignore</code> 过滤掉，否则就会一直跟着你的代码库各种变动。</p>
<blockquote>
<p>刚刚尝试在公司的代码库里 <code>find . -name .DS_Store | wc -l</code> 搜了一下，发现了整整 100 个 <code>.DS_Store</code> 🤷‍♀️</p>
</blockquote>
<h1 id="0x04-功能缺失三方工具大行其道">0X04 功能缺失，三方工具大行其道</h1>
<p>macOS 其实有很多常用功能并不完善，所以诞生了很多小工具来专门给苹果擦屁股（其实 iOS 也一样）。下面举几个例子</p>
<h2 id="finder">Finder</h2>
<p>Finder 是 macOS 中的文件管理器，我之前用了那么多年的 Windows，也用了几年的 Linux（Gnome、KDE、Xfce 都长期用过），从来没想过安装一个第三方文件管理器，因为他们都足够好用。只有到了 macOS 上之后，没多久我就开始探索第三方的文件管理器，先后尝试过 QSpace 和 ForkLift。为什么呢？当然就是单纯的 Finder 不好用啊 👎</p>
<h2 id="topbar">Topbar</h2>
<p>用过 Windows 的肯定都知道，打开的程序如果可以后台驻守的话会放在任务栏右侧，还可以通过系统设置让每个程序从固定显示、固定隐藏、条件显示三个状态里选一个。macOS 呢？完全没有，只要驻守在后台的程序全都在 Topbar 的右侧堆积着，你有三两个程序还好，十个八个的话就直接占据了一半的 Topbar，丑的很。重点是很多应用其实使用频率并不高，或者说都是通过快捷键调用的，从来不会在 Topbar 上去点，结果却要永久性占据一个位置。</p>
<p>而且说到这个就来气，新的 MacBook 给搞了个刘海，笔记本电脑，搞了个刘海，我不理解。最气的是这个狗屁刘海只有硬件知道，软件是不知道的。这意味着什么？意味着 macOS 并不知道你看不到刘海底下的内容，也就意味着当你的程序开的多的时候就会被挤到刘海里，然后你看不到它，看不到也就点不到。厉害吧，这就是优雅的 Apple 🤷‍♀️</p>
<p>那有什么办法可以让他们不长期驻守在那儿吗？比如说像 Windows 一样折叠起来？有的，你去搜一下就会看到很多人在推荐一个软件叫做 Bartender 的软件，它专职做这个工作。你开开心心把它下载下来发现：这个软件要 TMD 卖 $20，整整 TMD 20 dollars ！！！</p>
<blockquote>
<p>这时候就有果粉要说了：「你不知道别乱说，明明还有开源免费的 <a href="https://github.com/dwarvesf/hidden" target="_blank" rel="noopener noreffer ">hidden bar</a> 可以用呢」。啊确实，我就在用这个（反正不可能让我花 $20 隐藏一个图标） ，但是这东西不是苹果官方应该做的吗？？？</p>
</blockquote>
<h2 id="terminal">Terminal</h2>
<p>接下来是 Terminal，很多果粉在说 「macOS 是最适合程序员的系统」，那么我作为一个程序员就只配用这么烂的一个 Terminal 吗？Linux 桌面环境的 GNOME Terminal 或者 Konsole 和 Xfce Treminal 都比 macOS 官方提供的好用太多了。</p>
<p>不过好在 Terminal 没有太多收费的，很多都是开源项目，我这里推荐几个自己用过且好用的吧：</p>
<ul>
<li><a href="https://sw.kovidgoyal.net/kitty/" target="_blank" rel="noopener noreffer ">Kitty Terminal</a> 高性能，使用配置文件，功能完备</li>
<li><a href="https://alacritty.org/" target="_blank" rel="noopener noreffer ">Alacritty</a> 高性能，使用配置文件，极简</li>
<li><a href="https://iterm2.com/" target="_blank" rel="noopener noreffer ">iTerm 2</a> 传统、功能完备、性能说得过去</li>
</ul>
<h1 id="0x05-万恶的-command--q">0X05 万恶的 Command + Q</h1>
<ul>
<li>Windows 上切换不同窗口的快捷键是 Alt + Tab</li>
<li>Linux 上切换不同窗口的快捷键是 Alt + Tab</li>
<li>macOS 上切换窗口的快捷键是 Command + Tab</li>
</ul>
<p>看似非常和谐（macOS 的 Command 其实就是 Windows 的 Alt），但是 macOS 中有一个类似于 Windows 中 Alt + F4 的强制退出快捷键：Command + Q。熟悉键盘键位的小伙伴应该已经发现了，Q 和 Tab 是 TMD 挨着的！是 TMD 挨着的！哪怕是你再熟悉键盘，盲打再怎么熟练，也有可能手抖按错一个键吧，那么极有可能出现你想切换窗口时直接把当前窗口 Kill 掉的情况。</p>
<p>我不理解为什么要把「关闭窗口」 和「切换窗口」两个快捷键搞的这么近，难道产品经理（或者说是乔布斯？）自己从来没有误触过吗？别的快捷键误触也就算了，但是把切换窗口误触成关闭窗口后果可是有点严重的啊。</p>
<blockquote>
<p>我不信哪个长期用 macOS 的没出现过切换窗口不小心把窗口关掉的情况，绝对不可能 ❌</p>
</blockquote>
<h1 id="0x06-源自心底的傲慢">0X06 源自心底的傲慢</h1>
<p>我们都知道在文件管理器的「网络」目录里可以看到同一个局域网内的其他设备，那么我们来看一下 macOS 是怎么表现「其他」设备的。</p>
<p></p>
<p>没看清？放大看一下</p>
<p></p>
<p>是的你没看错，就是一个老式 CRT 显示器甚至还有些发黄了，运行着一个蓝屏了的 Windows 系统。那么 macOS 是如何展示自己的设备呢？</p>
<p></p>
<p>是的，不仅区分了 Mac mini，MacBook 和 iMac，甚至区分了不同的 MacBook，每一个都是那么的现代且美观。苹果你真的有必要这样吗？</p>
]]></description></item><item><title>如何高质量地接入 AI</title><link>https://blog.programmer.work/posts/how-to-integrate-ai/</link><pubDate>Thu, 06 Feb 2025 14:20:00 +0000</pubDate><author>Shawn</author><guid>https://blog.programmer.work/posts/how-to-integrate-ai/</guid><description><![CDATA[<h1 id="0x00-没有什么意义但我就是想写的前言">0X00 没有什么意义但我就是想写的前言</h1>
<p>有一说一现在的大模型发展太快了，最开始我列这个大纲的时候是把 deepseek 作为「凑合能用但超级便宜」的一个国产替代品来介绍的，没想到过了个年它直接翻身了，现在甚至能打 GPT-4o。所以我决定现在立刻马上把这篇文章写完，否则没准又杀出来个什么模型，会导致我永远写不完了 🤣</p>
<p>这篇文章的主要受众群体如下：</p>
<ol>
<li>知道最近 AI 很火，想用用看但是不知道怎么上手的朋友</li>
<li>尝试用过一些大模型，但是觉得接入不方便或者价格高的朋友</li>
<li>想全面接入 AI，让 AI 成为自己得力助手的朋友</li>
</ol>
<p>这篇文章会介绍这些内容：</p>
<ol>
<li>成品工具：只需要一个浏览器或者一个 APP 即可访问的最大众化的 AI 接入模式</li>
<li>模型选择：列举常见模型的特点，根据你的需求选择合适的大模型</li>
<li>API 接入：不方便接入原生 Claude/OpenAI API 时的优秀替代品</li>
<li>三方工具：通过 API 接入后能大幅改善日常使用体验的一些工具</li>
<li>本地部署：有关本地部署的一些个人看法</li>
</ol>
<p>那么废话少说，现在开始正文了</p>
<h1 id="0x01-商业化成品工具">0X01 商业化成品工具</h1>
<p>想要最快速的接入 AI 能力，那首选的自然是现成的商业化的 2C 产品了，所以我这里收集了几个我自己用过的比较好用的的商业化成品工具。</p>
<blockquote>
<p>注意这部分只讨论产品，不讨论模型，有关模型的讨论放在下面一个段落。</p>
</blockquote>
<h2 id="chatgpt">ChatGPT</h2>
<p>首先，自然是目前大模型的领军人物 OpenAI 了，它的 ChatGPT 目前应该是全球范围内最知名的 AI 工具了。目前 ChatGPT 提供了多种模型可选，也提供了多模态模型和联网搜索功能，部分高级模型需要付费使用，费用一般是 $20/mon。</p>
<blockquote>
<p>在 PC/Mac/Android 上使用 ChatGPT 需要有正确的上网姿势，在 iPhone 上还需要一个海外 Apple ID。并且注册起来也比较麻烦。如果切实需要的话可以在网上自行搜索一下注册教程。</p>
</blockquote>
<ul>
<li>访问方式：web、app、PC/Mac 客户端</li>
<li>优势：APP 使用体验极佳、够聪明、多模态；</li>
<li>劣势：访问难度高、价格贵；</li>
</ul>
<p>综合推荐等级：★★★★☆</p>
<h2 id="claude">Claude</h2>
<p>Claude 是追着 ChatGPT 打的另一个海外巨头，个人认为综合能力上略次于 ChatGPT 但不明显。不过同样的注册、访问都会有些麻烦。但是有一个上下文超长且比较便宜的模型（Claude-3.5-sonset-200k），可以让他阅读超长的 pdf、 MS office 等文档。同样的提供了更高级的付费模型，价格为 $20/mon。</p>
<ul>
<li>访问方式：web、app、PC/Mac 客户端</li>
<li>优势：聪明、多模态、比 ChatGPT 访问轻松一些；</li>
<li>劣势：访问难度依然较高、价格贵；</li>
</ul>
<p>综合推荐等级：★★★☆☆</p>
<h2 id="豆包">豆包</h2>
<p>豆包是字节跳动旗下的 AI 工具，目前我亲测下来说实话聪明程度明显弱于 ChatGPT/Claude，但是它强就强在免费和体验优良。首先它内置了很多个不同 prompt 的「人」，可以作为你的助手，这一点对于不会写 prompt 的新手来说很是实用。手机的 APP 还能通过语音对谈的方式和豆包交流，虽然 ChatGPT 也有这个功能，但是在国内使用豆包反应更快并且口语听起来舒服很多很多。macOS 上的客户端可以启用一些插件功能，实现划选文字进行翻译、解释等功能。</p>
<ul>
<li>访问方式：web、app、PC/Mac 客户端</li>
<li>优势：多模态、接入容易、语音体验良好、内置 prompt、免费；</li>
<li>劣势：不够聪明、进阶使用体验较差；</li>
</ul>
<p>综合推荐等级：★★★★☆</p>
<blockquote>
<p>建议所有人在手机上装一个豆包，毕竟是免费的，有事没事跟他硬聊几句都还是划算的。而且它也能联网，所以快速搜索一些确定有结果的问题也很好用。</p>
</blockquote>
<h2 id="deepseek">deepseek</h2>
<p>deepseek 这几天可真是爆了（以至于我一直在用的超快的 API 突然变慢了 😮‍💨）。简单介绍一下 deepseek 也是国产的，他们最擅长使用超低的成本做相同的事，最近刷屏的新闻也正是他们用了 GPT-o1 大概 2% 的成本训练出来了几乎相同水平的 DeepSeek-R1 模型。目前来说 deepseek 的重心还是在技术上，所以他们的客户端/web依旧停留在「能用」的水平线上。</p>
<ul>
<li>访问方式：web、app</li>
<li>优势：免费、多模态、接入容易、聪明；</li>
<li>劣势：应用层做的不够好、使用人数激增导致响应变慢；</li>
</ul>
<p>综合推荐等级：★★★★☆</p>
<h2 id="kimi">kimi</h2>
<p>kimi 是比较早火起来的国产 AI，当时的主要卖点是联网搜索。</p>
<ul>
<li>访问方式：web、app</li>
<li>优势：免费、多模态、接入容易、联网搜索能力强、app 体验好；</li>
<li>劣势：不如 DeepSeek-R1 聪明；</li>
</ul>
<p>综合推荐等级：★★★☆☆</p>
<h2 id="poe">POE</h2>
<p><strong>POE：我们不生产模型，我们只是大模型的搬运工</strong></p>
<p>POE 是一个集成了大量模型第三方应用，在这里可以付一份钱同时使用几乎所有的热门模型。例如你想同时使用 ChatGPT 和 Claude 的高级模型，觉得同时买两个会员太贵了，就可以同样花 $20 购买 POE 的会员，这样一来就可以同时访问他们了。但需要注意的是，POE 的逻辑是会员每月送你 1000000 「点数」，每次对话会根据模型的不同消耗不同的点数（一般都是够用的，我比较高强度使用都是够的）。这也是我目前唯一付了年费的 AI 订阅项。</p>
<ul>
<li>访问方式：web、app、PC/Mac 客户端</li>
<li>优势：访问所有热门模型（包括文生图模型）</li>
<li>劣势：付费、使用次数有限（尽管限制很宽松）</li>
</ul>
<p>综合推荐等级：★★★★☆</p>
<h2 id="综合">综合</h2>
<p>综合看下来，我可以做出下面的推荐：</p>
<ul>
<li>如果你只是想用最简单的方式体验一下AI，并且希望它足够简单易用，那就选豆包</li>
<li>如果你想使用目前最强的免费 AI 模型，同时愿意学习 AI 的用法，那就选 deepseek</li>
<li>如果你想接入世界先进的 AI 模型，那就考虑订阅 ChatGPT（ChatGPT 如果不订阅的话不如直接用 deepseek）</li>
<li>如果你想体验更多热门模型，想要了解不同模型的区别和擅长的方向，也想要深入学习使用大模型，那建议订阅 POE</li>
</ul>
<h1 id="0x02-通过-api-接入">0X02 通过 API 接入</h1>
<p>上面我们聊的都是点击即用的成熟的商业化产品，现在来讨论一下通过 API 来接入这些模型。</p>
<blockquote>
<p>提示：如果你听不懂 <code>API</code>、<code>base_url</code>、<code>API KEY</code>、<code>HTTP Method</code>、这几个词就意味着你暂时不适合下面的内容，继续阅读下去可能会感到有些蒙圈，这是正常现象 🤣</p>
</blockquote>
<p>首先我来介绍一下为什么我们需要通过 API 接入大模型，有如下几个优势：</p>
<ul>
<li>价格：例如 ChatGPT 的价格是 $20 每月，如果你只是每天对话个十次八次的，直接开通 Plus 会显得很亏，因为 ChatGPT Plus 是按月付费的。但是 API 则是按量付费，计费方式从每月固定额度变成了根据交互的 tokens 数量计算，在用量不大的情况下会更便宜；</li>
<li>性能：虽然没有直接证据，但是我体感上各家的 2C 产品使用的服务器和 2B 的 API 使用的服务器并非同一组，手机 APP 访问已经在卡了但是通过 API 访问就还是比较快；</li>
<li>定制：通过 API 访问可以自己调整更多的参数，例如影响记忆力和费用的 <code>max_tokens</code> 和影响输出的 <code>temperature</code> 等；</li>
<li>体验：使用 API 访问即使只是使用最基础的对话功能，我们也有多个前端工具可以选择，不会像官方的客户端一样没有半点定制化空间；</li>
<li>扩展：我们可以将 API KEY 配置到很多支持的工具上，让工具们获得 AI 的能力加持（例如 obsidian、Firefox/Chrome 等）；</li>
</ul>
<h2 id="模型选择">模型选择</h2>
<p>目前通过 API 接入的话我个人只推荐 deepseek、GPT、Claude 这三个。下面是每个家族的代表和他们的能力（主观评价）和价格的对比。</p>
<table>
  <thead>
      <tr>
          <th>名称</th>
          <th>能力（5分制）</th>
          <th>上下文</th>
          <th>输入价格（每百万 Tokens）</th>
          <th>输出价格（每百万 Tokens）</th>
          <th>备注</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>DeepSeek V3</td>
          <td>3</td>
          <td>64k</td>
          <td>$0.27</td>
          <td>$1.10</td>
          <td>价格无敌，配置在浏览器扩展上用于翻译和总结非常合适</td>
      </tr>
      <tr>
          <td>DeepSeek R1</td>
          <td>4.5</td>
          <td>64k</td>
          <td>$0.55</td>
          <td>2.19</td>
          <td>性价比无敌，能力媲美贵它将近 30 倍的 GPT-o1</td>
      </tr>
      <tr>
          <td>GPT-4o</td>
          <td>3.5</td>
          <td>128k</td>
          <td>$2.5</td>
          <td>$10</td>
          <td>-&ndash;</td>
      </tr>
      <tr>
          <td>GPT-o1</td>
          <td>4.5</td>
          <td>200k</td>
          <td>$15</td>
          <td>$60</td>
          <td>-&ndash;</td>
      </tr>
      <tr>
          <td>Claude-3.5-sonset</td>
          <td>4</td>
          <td>200k</td>
          <td>$3</td>
          <td>$15</td>
          <td>-&ndash;</td>
      </tr>
  </tbody>
</table>
<p>目前我自己的体验下来，推荐如下：</p>
<ul>
<li>DeepSeek V3 价格最便宜，充 10 块钱可以用很久。适合将它配置到一些支持 AI 的工具上，用来总结文章、大段翻译等。虽然它不够聪明但是足够便宜，随便调用也不用心疼自己的钱包；</li>
<li>DeepSeek R1 目前使用体验良好，足够聪明价格也是很便宜。如果不嫌弃它每次都要思考半天的话（其实这是它的优势项），可以作为主力 AI 模型使用，它理论上更擅长数学、编程等逻辑性强的工作；</li>
<li>GPT-4o 是传统模型中很强的了，没有 o1 和 R1 的推理过程，反应比较迅速。价格虽然比较贵但多少能承受，也是主力 AI 模型的一个优秀备选；</li>
<li>GPT-o1 应该是这些模型里理论最强的，但是这个价格嘛也很离谱。如果你在意它比 R1 强的那一点能力且不在意这 30 倍的价差，那 GPT-o1 是个不错的选择；</li>
<li>Claude-3.5-sonset 最大的优势是 200k 的上下文，是目前热门模型中上下文窗口最大的一个。如果你经常有大上下文的需求那么 Claude-3.5-sonset 是一个优秀的选择；</li>
</ul>
<blockquote>
<p>有关 tokens 和上下文：</p>
<p>我们在和大模型交互的时候，我们自己说的文字和大模型返回的文字都会被分词，然后将分词之后的结果作为 token 计算。例如我给模型提供一个 10 万个汉字的文档，让他回答我的一个问题，AI 的回答大概是 1000 个汉字的话，大约会消耗掉 10 万个 tokens。</p>
<p>上下文则是我们和模型对话时 AI 能处理的最大 tokens 数量。上面的例子一次对话就需要消耗 10 万个 tokens 也就是 100k 左右，也就意味着 DeepSeek V3/R1 都无法处理这个对话请求，但是 GPT-4o/o1 和 Claude-3.5-sonset 都能处理。</p>
</blockquote>
<h2 id="如何接入">如何接入</h2>
<p>众所周知，接入 AWS 的 API 就需要 AWS 的账号，但是现在的 AI 接入方式多少有些不一样的地方。当然通过 OpenAI 官方接入 OpenAI 的模型是天经地义的，但是我们国内用户光是注册 OpenAI 和 Claude 的账号就已经很费劲了，后面付费还有一座大山拦路，着实是整不动。所以在官方接入的传统方式之外还可以通过转发站点实现 API 接入，这种接入方式不仅注册和付费更轻松，还会有些许优惠。这里介绍两个站点：<a href="https://burn.hair/" target="_blank" rel="noopener noreffer ">头顶冒火</a> 和 <a href="https://gpt302.saaslink.net/M8oaa5" target="_blank" rel="noopener noreffer ">302.ai</a>，这两个平台类似，都是类似于前面介绍的 POE 的平台，只不过这两个平台提供的是聚合的 API 服务，在这一处充值后能通过 API 访问平台支持的模型。</p>
<p>如果你想通过 API 的方式接入 DeepSeek 的话就不需要再用上面的服务中转了，直接去官网注册账号然后支付宝微信付款用就行了。</p>
<blockquote>
<p>另外有个好消息，目前已知的绝大多数大模型的 API 都兼容 OpenAI 的 API 标准，也就意味着绝大多数能使用 OpenAI API 的工具都能通过修改 <code>base_ur</code>, <code>API KEY</code>, <code>model</code> 这三个参数的方式快速接入。</p>
</blockquote>
<h1 id="0x03-第三方工具">0X03 第三方工具</h1>
<p>使用第三发工具的前提是通过 API 访问大模型，个人认为这才是当前大模型的完整使用方式。下面介绍几个自己真正用过的第三方工具：</p>
<h2 id="glarity">glarity</h2>
<p>这是一个浏览器扩展，配置好 API 之后它会有一个悬浮按钮在浏览器里，可以一键快速调用大模型对当前页面进行总结，也可以针对当前页面进行提问，还可以做到在尽力维持页面布局的情况下实现逐行翻译。强烈推荐所有可以通过 API 访问大模型的朋友安装试用。</p>
<h2 id="chatgpt-next-web">ChatGPT-Next-Web</h2>
<p>这是一个简单的聊天工具，不管是 DeepSeek 还是 ChatGPT 他们都有自己的页面，但是通过 API 访问的话总不能就在命令行里用吧。所以 ChatGPT-Next-Web 就出现了，它就是一个可以创建多个对话也能上传文件的前端工具，给它配好 API 就能像普通客户端一样使用 API 了。值得表扬的是这个开源项目可以部署在服务器上，通过浏览器访问，效果非常棒。也就意味着你可以自己开通 API 后把它部署在公网服务器上，配置一个密码，就能让自己和家人朋友一起用了。</p>
<h2 id="obsidian">Obsidian</h2>
<p>如果你也用 Obsidian 的话可以给你推荐一个名为 Text Generator 的插件，这个插件配置好之后可以在 Obsidian 中调用 API。可以实现的功能包括但不限于：选中大段文字让他检查错误、总结整篇笔记、生成某某的介绍等。虽然不如 Notion 的 Notion AI 集成度那么高，但是体验也还是不错的。</p>
<h1 id="0x04-本地化部署">0X04 本地化部署</h1>
<p>最后再聊一聊本地部署吧，最开始的时候我尝试过在 MacBook 上部署 Llama 3.1 的 7B 和 14B 模型测试。最近 DeepSeek R1 的突然爆火也开始出现了大量的本地部署的教程，给人一种在本地部署之后就不需要联网使用官方服务的感觉。</p>
<p>我自己测试的硬件配置是一台 M2 Max 32G 的 MacBook Pro，按理说跑大模型的性能应该是超出大多数朋友的电脑的。就以最近我测试的 DeepSeek R1 为例，简单测试的结果如下：</p>
<table>
  <thead>
      <tr>
          <th>模型</th>
          <th>效果</th>
          <th>速度</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>DeepSeek R1 7B</td>
          <td>一般</td>
          <td>飞快</td>
      </tr>
      <tr>
          <td>DeepSeek R1 14B</td>
          <td>一半</td>
          <td>飞快</td>
      </tr>
      <tr>
          <td>DeepSeek R1 32B</td>
          <td>可以非严肃环境使用</td>
          <td>比较快</td>
      </tr>
      <tr>
          <td>DeepSeek R1 70B</td>
          <td>跑不动</td>
          <td>跑不动</td>
      </tr>
  </tbody>
</table>
<p>并且即使我跑 32B 这样的模型，效果也并不够看。所以我自己的个人看法就是：</p>
<ul>
<li>如果你只能跑 7B 或者 14B 的模型，那可以用来学习、体验、图一乐</li>
<li>如果你能跑 32B 的模型，那可以用来正经聊聊，但是能力依旧有限，不适合严肃环境使用</li>
<li>如果你能跑 70B 的模型，那&hellip;&hellip;我没试过，不知道能力怎么样 🤣</li>
<li>如果你能跑 671B 的模型，那请你联系我，我想和土豪做朋友</li>
</ul>
<p>如果要在本地部署的话，目前比较推荐的就只有 DeepSeek 和 Llama 了，并且在模型选择上基本 32B 就到头了，如果是自己本地跑跑玩玩的话建议从 7B 和 14B 中进行选择，最多最多试试 70B（如果是 Mac 的融合内存的话）。</p>
<blockquote>
<p>最后悄悄说一下，本地部署的话可以了解一下带有 <code>abliterated</code> 标签的模型，这才是本地部署模型最大的意义。</p>
</blockquote>
]]></description></item><item><title>2024 年度总结</title><link>https://blog.programmer.work/posts/2024-summary/</link><pubDate>Fri, 17 Jan 2025 14:04:45 +0000</pubDate><author>Shawn</author><guid>https://blog.programmer.work/posts/2024-summary/</guid><description><![CDATA[<h1 id="0x00-碎碎念">0X00 碎碎念</h1>
<p>数数看这已经是我的第六篇年度总结了，每当回过头去看之前的总结就感觉写这些也还挺有意义的。虽然写日记对我来说太困难了，但是写「年记」好像还行，甚至有点乐在其中 🤔</p>
<p>廖凡_饺子_姜文.mp4</p>
<p>说起来小学时候大家都不喜欢家庭作业里有日记这一项，因为要写好多字，而且都没什么可写的。我就不一样了，因为我小学时候的日记全文都是：今天去XXX玩了，很高兴/今天去XXX家写作业，很开心。 🤣</p>
<p>回到正题。今年的生活完全被打乱了，比疫情还在的时候更乱，以至于我第一次 delay 了我的年度总结。哦不是，是完全没有去检查年初制定的计划到现在完成了多少（估计有个 30% 就谢天谢地了），具体是什么情况导致的我后面再说吧。这次给博客列的大纲就是零零散散不成体系，只能说尽力拼凑了一个年度总结出来，不管是长度还是质量肯定是不及去年和前年的万字长文了。那么就直接开始吧。</p>
<h1 id="0x01-专业能力">0X01 专业能力</h1>
<p>今年本来的计划是更多的去深入学习之前已经掌握的知识和技能，结果完全没深入哪里去。反倒是之前两年多次「下定决心」要学的 Go 在今年突然用在工作上了，感觉之前自己吭哧吭哧看了半天不如真正工作上用起来一个星期提升来得快。</p>
<p>也正是这一点，让我对学习专业技能上有了一个新的想法：暂时用不上的知识和技能当然要学，只是不用那么纠结自己到底明白了多少（反正用不上的话也很快就忘记了），只需要做到「我知道有什么，我知道是什么」就行了，等真用到了再去根据自己的那一点点基础去学就好了。反正我的 Docker 和 MySQL 这些都是这样学来的。</p>
<p>比如 Docker，最开始学的时候是在学校里，完全没有使用 docker 的需求，以至于甚至搞不清楚 docker 和虚拟机有什么区别，也不理解为什么 ubuntu/fedora 这些我常用的发行版本里面连个 vim 都没有，<code>systemctl</code> 也没法用。但好在最基础的用法（尤其是在工作环境里）你并不需要从零去完整的学一整个东西，都是在别人的基础之上进行操作的。</p>
<blockquote>
<p>⚠️ 并不是说专业能力不需要从头学起，只是说最开始的阶段没必要死扣那些细节，先用起来就行。但是如果你都用了很久 docker 了，还是说不出 docker 和虚拟机的核心区别，还是不清楚为什么 ubuntu 镜像里不带 systemd 和文本编辑器，那就不应该了。</p>
</blockquote>
<h1 id="0x02-出游">0X02 出游</h1>
<h2 id="广州佛山">广州、佛山</h2>
<p>这次本质上是一次出差，但是解决的确实一个非常简单的问题，不过又由于各种情况导致在佛山停留了一周之久。正好又赶上周末，所以可以算是半个旅行了。也正是这次过去出差也才知道，原来广州的地铁可以直接通到佛山的 🤯。</p>
<p>作为一个博物馆爱好者，到了省会城市肯定会往省博跑，但是令我没想到的是诺大一个广东省博却没什么好看的东西 🥲。里里外外传下来都没看到什么让人「哇塞」、「卧槽」、「牛逼」的东西，反倒是看到了一个让我觉得「啊？」的东西：镇馆之宝&mdash;白切鸡 🤣。反倒是广州的「南越王博物馆」更有意思，推荐同样的博物馆爱好者过去看一看。</p>
<p>广东省博-白切鸡</p>
<p>虽然没去佛山博物馆，但是去了一趟祖庙看了黄飞鸿纪念馆和叶问堂。如果对那段人文历史比较感兴趣的朋友，可以去看一看，黄飞鸿纪念堂有高质量的舞狮表演，叶问堂有叶问用过的木人桩和八斩刀展示。</p>
<p>佛山-舞狮叶问-八斩刀</p>
<p>另外广东的吃的确实是不错，尤其是牛肉。印象很深的是去吃的一家潮汕牛肉。店门口有一个小黑板专门写了今天的牛肉是下午几点钟开始杀，几点钟送到店里的。肉质非常新鲜，配合清汤的锅底和各种酱料，感觉自己能吃好几盘 😋</p>
<p>你说广州塔？那肯定是去了的，但是水平有限导致并不能拍出别人随手拍的大片，只能起到一个纪念作用。</p>
<p>广州塔</p>
<h2 id="兰州">兰州</h2>
<p>兰州是因为去参加一对好朋友的婚礼（还兼职摄影摄像），所以时间比较紧张，没去玩很多地方。但是 <strong>兰州的羊肉是真的好吃！！！</strong> 玩的话就只去了水墨丹霞，地方不大但是好在去机场顺路，据说可以作为七彩丹霞的平替。</p>
<p>铜奔马水墨丹霞水墨丹霞</p>
<blockquote>
<p>有一说一，这场婚礼是我目前为止参与程度最最最高的一场，从前一天晚上的场地探查到第二天一早的新娘化妆，再到接新娘，上婚车，一直到最后吃的核心席。还真是第一次如此高强度满满当当的参加一场婚礼。说到这儿再次祝他们百年好合 🎉</p>
</blockquote>
<h2 id="雅安">雅安</h2>
<p>雅安离成都很近，这次是蹭了朋友的车过去的。当时找了一个在山上的观景台民宿（小木屋），过去放松了两天，感觉还不错。住宿环境和吃的都比较一般，但是推开房门就能看到非常漂亮的山景湖景，作为乏味生活的一点点调剂还是让人觉得豁然开朗。</p>
<p>雅安某湖</p>
<h2 id="芒市">芒市</h2>
<p>去云南芒市的旅行完全是因为当时超级烦躁，就在携程上看特价机票，发现到芒市的往返机票两个人才不到两千，就直接冲了，反而是这次纯纯瞎跑的旅行却成了今年最舒服的一次。</p>
<p>芒市大金塔</p>
<p>我们就只去了芒市的金塔和银塔，然后剩下的时间就在小城里乱走乱逛，累了就回民宿躺着，体验还是不错。吃东西印象最深的就是打车去「芒杏村」吃的烧烤了（果然哪里的烧烤都比成都好吃），价格优惠味道很棒。</p>
<p>如果有朋友也有兴趣去芒市的话，可以有两个小建议：金塔银塔距离很近，步行几分钟就能到，但是要分开收费（每张门票 40 元）。其中金塔重佛教，银塔重拍照，但是想要拍金塔的话反而是在银塔景区里更好拍。</p>
<p>芒杏村烧烤</p>
<p>另外一个建议就是「一定要去芒杏村吃烧烤」，虽然只吃了一家，但是滴滴师傅说周围的水平都差不多，而且非常好吃价格又便宜，强烈推荐。</p>
<h2 id="米仓山">米仓山</h2>
<p>米仓山是单纯去看彩林的，虽然没有隔壁光雾山知名但是风景却一点都不差。另外如果有成都朋友想去的话可以先坐高铁到汉中，然后再转车到米仓山。虽然米仓山在巴中，但是高铁到巴中再去米仓山反而耗时更久价格更贵。</p>
<p>米仓山</p>
<p>一个小攻略是可以提前一天晚上到米仓山景区门口，找地方住宿然后赶在景区开门的第一时间冲进去，这样玩的会舒服一些。而且景区门口吃饭的地方也很多，不用担心没有地方搞吃的。另外米仓山景区里有🚁直升机，只要 350 块！！！</p>
<h1 id="0x03-年度游戏">0X03 年度游戏</h1>
<p>让我们恭喜 宇宙机器人 获得 TGA 年度游戏大奖！！</p>
<p>开个玩笑，宇宙机器人确实是个好游戏，但是它在另外几个作品面前真的不配拿奖啊。</p>
<h2 id="黑神话悟空">黑神话：悟空🐒</h2>
<p>这一切要始于 2020 年 8 月 20 日，那天我到公司听说 B 站有一个国产游戏的预告片，当时没太当回事。后面看了之后汗毛炸起，但是突然就冷静下来了，心想：不可能的，这绝对是诈骗，国内能做出这种游戏就见鬼了。但实际上也正是这一刻开始，就期待了起来，有哪个中国游戏玩家不想在游戏里扮演大圣呢？</p>
<p>在此之后沉寂了很久，游科每到过年和 820 就都会放出一段新的预告宣传，随着时间推移心里的想法也早就发生了变化。从 2020 年的「我不相信能做出来」到 2024 年的「就算是一坨💩我也要尝尝咸淡」。</p>
<p>直到今年夏天，一觉醒来看到手机的 PS APP 提醒我愿望单里的《黑神话：悟空》可以预购了，我一下就清醒了，从看到消息到豪华版预购成功没有一秒钟的思考。</p>
<p>黑神话悟空</p>
<p>提前把假请好，前一天晚上把沙发整理好，给 PS5 手柄充上电，把饮料放在冰箱里，做好一切准备。第二天一大早起来关窗帘、拿饮料、调大音响音量，坐在电视前面拿好手柄眼巴巴看着 PS5 上面的倒计时，然后第一时间进入游戏。巧的是，当天朋友圈里好多人都跟我一样「遇到了不可抗力」导致没办法上班 🤷‍♀️</p>
<p>从早上十点游戏解禁，一直到晚上十二点打完虎先锋睡觉，中间几乎是没有任何休息时间。如果要用一句话来描述这个游戏，那只能是：「<strong>这是我二十年游戏生涯里，做梦都想玩到的游戏</strong> 」</p>
<h2 id="小丑牌">小丑牌🤡</h2>
<p>小丑牌是我玩过最好玩的卡牌游戏，推荐所有对卡牌或者 rouge like 游戏有兴趣的朋友上手！（不想说太多，三两句又说不清楚，所以干脆不说了。但是为了表示这个游戏真的很好玩，所以专门给他保留一个位置）</p>
<h2 id="跑车浪漫旅-7gt7">跑车浪漫旅 7（GT7）🚗</h2>
<p>为什么没有直接说 GT 7 而是特地强调了《跑车浪漫旅》的名字呢？因为这个名字翻译的真的太好了～在玩 GT7 之前我一度以为极限竞速地平线是最优秀的赛车游戏，不过现在起码在我心中「最佳赛车游戏」的头衔要易主了。</p>
<p>您的浏览器不支持 HTML5 视频标签。</p>
<p>游戏的驾驶手感超级棒，结合 PS5 的手柄让每一次油门刹车都倍感真实，甚至每次吃到路肩的时候是具体哪边吃了多少都能通过手柄精细化的震动感受到。制作人山内一典对车辆建模的变态追求让我在游戏过程中甚至区分不出真假（有 PS VR2 的加成），虽然车外的风景画质一般，但在驾驶高速赛车的时候也很难注意到风景就是了。</p>
<p>以前我觉得赛车游戏就应该像极品飞车那样，爽快刺激；后来玩了极限竞速地平线之后觉得最佳的赛车游戏应该去除哪些过于花哨的东西，还是需要刹车和走线的，而不是乱撞和漂移；现在我已经开始觉得赛车游戏就应该用方向盘视角，就应该注意刹车点了。（坏了，我不会要入坑赛车模拟器了吧）</p>
<h1 id="0x04-电影">0X04 电影</h1>
<p>这几年的电影都是些什么歪瓜裂枣&hellip;&hellip;</p>
<p>我以前晚上无聊的时候，时长掏出手机看看院线信息，然后晚上九点十点跑出去看个电影再回家。最近两年每次掏出手机看院线信息之后，都是叹口气然后关掉，真的是太烂了。</p>
<p><em>曾经～我茫然前行～暗夜的路上～</em></p>
<p>今年看过的华语电影只有两个说得过去的：《周处除三害》和《好东西》。前者其实只是一个合格的普通片子，但是之前大陆很少上这种暴力电影，这次就趁这机会去看了。后者则是一部女性视角的片子，但不是那种无脑打拳的电影，还是值得一看的。唯一问题就是里面的小孩儿，经常冒出来几句没有三四十年生活经验都总结不出来的金句，有点离谱了。</p>
<h1 id="0x05-运动">0X05 运动</h1>
<p>今年的运动之有前半年在坚持，后半年直接摆烂了。不过好在有两个里程碑式的运动成就：游泳算是学会了（蛙泳熟练，自由泳能游），自行车也骑了一个 170km 的小长途。</p>
<p>明年在运动上要多多投入时间了，计划的是徒步、跑步、骑车这三项，但是详细的年度计划还没列，等过几天确定了再看吧～</p>
<h1 id="0x06-ai">0X06 AI</h1>
<p>AI 的进步真的太快了，今年我用 AI 的时间应该远远大于 2023 年了（花的钱也远远高于 2023 年）。这里点名表扬几个在本年度里表现优异的 AI 小弟。另外我正在筹划写一篇有关在国内如何快速接入高质量 AI 的博客，到时候会详细介绍这些内容。（大纲写完之后发现一篇根本写不完，应该会拆成两篇甚至三篇）。</p>
<h1 id="0x07-读书">0X07 读书</h1>
<p>今年读的书应该是近几年最少的，简单挑几本有印象值得推荐的来说说吧</p>
<h2 id="拍出绝世佳作美姿光线">拍出绝世佳作/美姿/光线</h2>
<p>被书名影响了的摄影书神作，虽然书名看起来有点像《21 天精通 C++》一样的东西，但内容质量非常之高，豆瓣评分三本都在 8.5 上下。第一本是写给纯新手的，从各个角度拆分讲解了如何拍出一张好看的照片，后面两本是专精于人像摄影的。如果有兴趣的话这一套书是非常值得看的。（别问现在水平咋样，问就是行走的监控摄像头）</p>
<h2 id="如何屠龙">如何屠龙</h2>
<p>这本书的名字和上面的完全相反，光看名字就感觉很有意思。但她实际上是一本借由剑与魔法来讲述欧洲中世纪的历史书，非常有趣，对中世纪历史或者剑与魔法背景游戏感兴趣的朋友可以买来读一读。</p>
<p>如何屠龙</p>
<p>我看这本书的时候总把自己带入到上古卷轴 5/巫师 3 的游戏背景里去，代入感直接拉满 🤣</p>
<h2 id="克莱因壶">克莱因壶</h2>
<p>这本书被称为：日本虚拟现实 VR 题材开山杰作， 超前《盗梦空间》20年。但毕竟它太老太老了（1989年发行），以至于看起来里面很多地方都略显古板，不过如果喜欢看科幻、推理、悬疑、游戏的话，倒是值得一单。字数不算很多，一晚上就能看完。</p>
<blockquote>
<p>说这本书古板当然不是批评，因为它作为一本科幻小说确实足够「古」了，而且在它之后也有很多这种类似设定的小说电影面试，在走他的路子，后来者无数才会显得「古」的。就类似于你现在第一次去看搏击俱乐部，八成会觉得「又是精神分裂，看都看麻了」，那是因为它开创了一个品类，后来者甚多导致的。</p>
</blockquote>
<h2 id="doom-启示录">DOOM 启示录</h2>
<p>传奇程序员约翰卡马克和他的团队研发 DOOM 的故事。这本书读的我热血沸腾，而且时常觉得人与人的差距有时候比人与猪之间的差距还大。</p>
<p>DOOM 启世录</p>
<p>你说你不认识卡马克？他<strong>也就只是</strong> 创造了 FPS 游戏品类，开发了 DOOM、德军总部、Quake；开创了多人联机游戏；开创了 MOD 文化的一个<strong>普通程序员而已</strong> 。</p>
<h1 id="0x08-其他">0X08 其他</h1>
<p>依旧是把想要分享又不知道放在什么地方的一些东西放在这里了。</p>
<h2 id="iphone-15-plus">iPhone 15 Plus</h2>
<p><strong>垃圾苹果，60hz 刷新率 6G 内存的手机卖这么贵</strong> 。我其实没有被苹果所谓的绑架，只是单纯的觉得 iOS 虽然有很多很蠢的地方，但也有好多优势，让我想继续用 iOS。我甚至觉得 iPhone 如果只谈硬件那几乎就是一坨 🤷‍♀️</p>
<p>从 iPhone 12 mini 这种邪门的手机，换到 iPhone 15 Plus 这种邪门的手机，我这种人估计是不多。因为我觉得标准版再小也小不过 mini，再加上之前被 mini 的续航折磨到自闭，干脆就换了 Plus 版。iPhone 本身没什么好聊的，能用。唯一想夸一下的就是 Plus 的续航，我在电池设置里把它改成「只充电到 80%」之后每天都能正常使用到晚上睡觉，续航确实非常够我用了。也正是电池变大，导致我这一整年使用下来电池健康居然是 99% 🤯</p>
<h2 id="garmin-955">Garmin 955</h2>
<p><strong>垃圾苹果，号称运动手表结果电池连 170km 骑行的时间都坚持不下来</strong> 。这个 Apple Watch 我是真绷不住了，所以把它出掉换了佳明的正经运动手表。功能上的确缺失了很多，但是那些缺失的功能我本来就没怎么用过&hellip;&hellip;反倒是佳明的运动检测准确度、续航时间、更轻的重量、更快捷的按键操作让我感知明显。</p>
<h2 id="照片打印">照片打印</h2>
<p>我自己家里买了个小的照片打印机，日常的照片临时打印一下感觉还不错。但是如果你有多张照片想打印的话，还是推荐淘宝找店家。自己的小打印机速度慢不说，价格还高，一张相纸差不多两块钱，效果还不如店里打印的。我自己在淘宝找店里打印的照片 100 张只要 88 还包邮，印刷质量还比我自己打印机出来的好不少。唯一的问题就是你要把照片发给店家，如果极度在意隐私的话就没办法了。</p>
<h1 id="0x09-罪魁祸首">0X09 罪魁祸首</h1>
<p>让我觉得今年生活被完全打乱的罪魁祸首可能就是上半年接的私活了。确实，靠下班之后的时间和周末的时间赚到了一点钱，但代价是什么呢？代驾就是工作日下班回家休息一会儿就要再干两三个小时的活，周末也要至少干几个小时。其实按数量说并没有多干特别多工作，但是体验上就差了很多。本来回家打打游戏想的是「好快乐」，回家学习就算是写写自己的小项目想的也是「我真棒」，即使回家躺平也是「好舒服」，但是干活就会有一种很不爽的感觉。到现在为止我已经工作了六年多了，之前从来没有过想要请假去放松一下的时候，但是接了这个活之后就时不时冒出这种想法。</p>
<p>本来想的只是下班之后拿出一些时间来写写代码，赚点外快也挺好的。但是没想到的是客户隔三差五就会修改需求，而且他们自己都不清楚自己想做的到底是个什么东西，东改一改西改一改，整的人心力交瘁。最开始的时候我还在想「程序性能」「扩展性」「优雅」这些东西，到最后已经是「程序能跑就行」了。</p>
<p>这样一想，公司里有销售、售前、项目经理、产品经理、研发 leader 等很多岗位的支持和各种规范化流程还是很有必要的。私活很难有这些东西，就会导致开发过程非常的不顺利。</p>
<p>切实感受到了 <strong>钱难挣屎难吃</strong> 的前三个字（并不是很想感受后三个字）。</p>
<h1 id="0x0a-一点小思考">0X0A 一点小思考</h1>
<p>我之前下班到家总会在电脑前坐两三个小时，美其名曰「学习/读书」。确实，很多时候都是真的在学东西或者读一些书，但也正是这件事让我给自己上了一层无形的很大的压力。如果有一天我不想学不想看，就想玩游戏，那我大概率也会纠结着坐在那里用一种极低的效率去学习去读书，可能两个小时过去效果还不如平时二十分钟好。但这样做就会让我没有「负罪感」，因为我会告诉自己「我已经努力了，结果不好只是因为我状态不好，毕竟我都在这儿坐着看了两个小时了」；如果坐在沙发前玩一晚上游戏，虽然游戏是玩了，但是并不会快乐，一直会想着「本来应该去学习的，结果现在来打游戏了，果然我还是不太行」。</p>
<p>但是今年的后半段因为想着「反正今年的年度计划也乱七八糟了，而且搞这个私活整的挺累，还赚到了一点点外快，那不如直接摆烂一下吧」，就直接摆烂了。每天回家休息会儿就要么玩 PS5 要么刷 B 站，突然感觉这样好快乐（明明这才是绝大多数人的生活）。</p>
<p>也正是这个小经历让我决定在新的一年做出一些改变：默认情况下还是按之前的逻辑去学习和提升，但也不要过分要求自己「假装努力」，如果想玩想休息那就放宽心去就好了，<strong>少一些压力多一些快乐不是犯罪</strong> 。</p>
<h1 id="0x0b-明年会更好吗">0X0B 明年会更好吗？</h1>
<p>显然今年并不是很满意，而且一年下来不管是自己的专业技能、兴趣爱好还是日常生活都没有发生什么明显的变化。不过好在经过这一年的生活我已经慢慢懂得了如何进行自我调节，而且计划 2025 年会比 2024 年有<strong>多得多的变化</strong> 。借用官媒常用的一个词来说的话那就是<strong>稳中向好</strong> 🎉</p>
<h2 id="期待的游戏">期待的游戏</h2>
<p>另外 2025 年光是游戏就足够我期待的了。继村里第一个大学生直接上了清华之后，参与「明年高考」的学生也有一个看起来很有潜力的：《明末：渊虚之羽》。还有一个比较期待的是让我记住了一个并不符合我英语水平的单词的游戏： <em>Civilization VII</em> 。当然要说最期待的就是 <em>Unspeakable VI</em> 了，小学时候家里的电脑性能不够没法在迈阿密飙车，现在起码不会卡成 PPT 了 🤣。</p>
<blockquote>
<p>GTA 5 之后 12 年，GTA 6 来了；那么另一个 5 之后已经快 14 年了，6 呢？</p>
</blockquote>
<p>最后就是任天堂了，众所周知一款游戏机的生命周期基本上是七年。现在七年之期已到，你的新机器呢 😭 而且按理说一台新机的发布势必会伴随着护航大作的到来，之前给 switch 护航的就是旷野之息和马里奥奥德赛，我都不敢想这种级别的阵容再来一次能有多幸福 😭</p>
<h2 id="期待的电影">期待的电影</h2>
<p>比起游戏界的 2025 神仙打架，目前已知的 2025 电影几乎没什么能打的，自然也没什么期待。以前每年都要去个十次八次电影院，现在一年下来能去个三两趟都算是不少了 😮‍💨。</p>
<p>唯一一个期待的就是 2024 年初备案的电影《英雄出少年》，据说已经杀青了，是姜文导演编剧的新片。不过这个阵容我是一点都看不懂：姜文、马丽、葛优、赵本山、雷佳音，据说还有胡歌、宋小宝。虽然阵容看不懂但不妨碍继续期待。</p>
<h1 id="0x0c-总结的总结">0X0C 总结的总结</h1>
<p>根据我一向的「好习惯」，一定是要给总结写一个总结的。但是我对今年的满意度真的很低，以至于没有什么太大的兴趣再总结一次了。但是明年也就是 2025 年，就要迎来我的 30 周岁生日了，向着 30 周岁发起冲锋吧！（突然中二起来了）</p>
]]></description></item><item><title>2024 年的自建 NAS 不专业不完全手册</title><link>https://blog.programmer.work/posts/nas-build-2024/</link><pubDate>Tue, 02 Jul 2024 13:48:00 +0000</pubDate><author>Shawn</author><guid>https://blog.programmer.work/posts/nas-build-2024/</guid><description><![CDATA[<h1 id="0x00-你需要一台-nas-吗">0X00 你需要一台 NAS 吗</h1>
<p>不知怎么的，在移动互联网疯狂发展的今天，反而慢慢开始兴起了自建网络服务这种复古风潮。最近这些年身边的朋友同事越来越多聊到 NAS 了，甚至 B 站上出现了一小撮 NAS 区 UP 主（没错，你知道我说的是谁）。就更不说现在淘宝咸鱼上大量的 NAS 专用机箱，甚至是 3D 打印的定制化版本了。</p>
<p>你真的需要一台 NAS 吗？NAS 说白了就是一块连着网的硬盘，速度比直接插电脑上还慢一些，如果你平日里需要访问数据的设备并不多，且拥有一个台式电脑，那不如先买两块硬盘插上去。通过文件共享功能将台式机转换成一个带有存储功能的兼职 NAS。</p>
<p>如果你家里的多个手机、平板、电脑、电视都需要访问存储，或者你没有台式机可以扩容，那确实可以考虑搞一台 NAS。</p>
<p></p>
<p>我自己的需求是这样的：</p>
<ul>
<li>平时喜欢摄影，每次拍摄回来的照片少则 10G 多则 50G，日积月累已经有大几百 G 了，需要备份</li>
<li>也喜欢拍一些视频，相机拍摄的码率都很高，随随便便 50G 100G 的，需要备份</li>
<li>患有仓鼠症，喜欢囤一些高清电影电视剧来看，总共搞了有差不多 8T 了</li>
<li>手机、平板、电视、电脑都需要访问上面的影视资源</li>
</ul>
<p>什么，你说你就是想要，不管需求？那就买呀，挑着贵的和好玩的买～</p>
<h1 id="0x01-我的-nas-之路">0X01 我的 NAS 之路</h1>
<p>最早的一台 NAS 是 2018 年买的 Synology DS118 性能烂到家了，也只有一个盘位，配了一块 4T 红盘，不过还是老老实实用了差不多 3 年。</p>
<p>DS118 存储告急之后打算升级 NAS，觉得自己很少用得上群晖引以为豪的软件，再加上对自己的技术实力有一捏捏🤏的信心，所以开始尝试自组 NAS。硬件选择了奔腾 G6400 + 16G 内存，第一次使用了 OMV ，觉得它对 Linux 的改动很少，所以相对来说更玩得惯。不过用了没多久还是换成了 TrueNAS Core，这套平台就稳定运行了很久。</p>
<blockquote>
<p>当时买了 8T 的 HC320，买了没几天奇亚币就上天了，我的硬盘价格也跟着上天了。时隔一周，我 899 买的硬盘店家就卖 1899 了 🤷‍♂️</p>
</blockquote>
<p>因为 TrueNAS Core 是基于 BSD 的系统，后来看 TrueNAS SCALE（基于 Linux 的）稳定了之后就切到了 SCALE 版本，也顺势将 G6400 升级成了 i3-10100，内存也加到了 32G。</p>
<p>升级之后的 NAS 一直稳定运行到了今年，突然有一天我觉得家里另外一台用作 homelab 的服务器开机时间太少了，然后我看着身边的一台性能「强劲」的 homelab 和一台性能「羸弱」的 NAS 陷入了沉思。沉思过后，从兜里掏出了一张「融合」：</p>
<p></p>
<h1 id="0x02-有点强的硬件配置">0X02 有点强的硬件配置</h1>
<p>说是融合，其实就是选用了 homelab 的 CPU内存主板和原 NAS 的机箱硬盘，大概配置如下</p>
<table>
  <thead>
      <tr>
          <th>Name</th>
          <th>Model</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>CPU</td>
          <td>AMD Epyc 7551P 32C64T</td>
      </tr>
      <tr>
          <td>主板</td>
          <td>SuperMicro H11SSL-i</td>
      </tr>
      <tr>
          <td>内存</td>
          <td>DDR4 16G ECC * 4</td>
      </tr>
      <tr>
          <td>HDD</td>
          <td>HC320 8T * 3</td>
      </tr>
      <tr>
          <td>HDD</td>
          <td>红盘 4T * 1</td>
      </tr>
      <tr>
          <td>HDD</td>
          <td>银河 4T * 1</td>
      </tr>
      <tr>
          <td>SSD</td>
          <td>Intel 1.6T</td>
      </tr>
      <tr>
          <td>网卡</td>
          <td>Intel 2.5G</td>
      </tr>
      <tr>
          <td></td>
          <td></td>
      </tr>
  </tbody>
</table>
<p>试问哪个程序员不想要一台 32 核 64 线程 64G 内存 近 30T 存储容量的 NAS 呢 🤣</p>
<blockquote>
<p>配置单疑点：真有必要上这种 CPU 吗？没有，完全没有，事实上是之前 i3-10100 应付我的需求也完全没有任何问题。我只是正好有这个，卖也不怎么值钱，不如装上。真有必要上 64G 内存吗？没有，完全没有，事实上之前 32G 内存 应付我的需求也完全没有任何问题。我只是&hellip;有点上头，所以上了 64G。真有必要搞这么多存储吗？没有，完全没有，事实上🤦‍♂️这个还是有的，或者说因人而异，毕竟我确实要存好多照片、视频和电影电视剧。听说 HC320 很拉？其实我没觉得，所谓炒豆子声确实存在一些，不过也只存在于读写的时候，但是 NAS 其实大多数时候磁盘是可以休眠的。另外我放在桌子下面使用完全不会在意，只要别放卧室就没有问题。你那个 1.6T 是不是有点扎眼？这是我在咸鱼上收的二手，当时放在 homelab 上用的，现在拿过来做缓存（缓存意味着丢了也问题不大），正经自己配置缓存的话一般 250G 就妥妥够用了。</p>
</blockquote>
<h1 id="0x03-硬件选择">0X03 硬件选择</h1>
<p>我这个硬件配置其实也就图一乐，对大多数朋友的选购并不能起到多大的帮助作用。这一节来简单帮大家分析一下需求，选择自己需要的配置。</p>
<h2 id="cpu">CPU</h2>
<p>如果没有万兆传输需求，那 300 块钱买一个 G6400 或者同等水平的 CPU 就可以了，如果有万兆需求的话可能 CPU 性能上需要再上一档。</p>
<p>另外挑选 CPU 的时候可以注意一下它的编解码性能，如果性能达标的话在 NAS 上做视频转码就舒服多了。</p>
<h2 id="内存">内存</h2>
<p>内存主要就是看大小，如果你不打算用 TrueNAS 且不打算跑好多个服务在 NAS 上的话，4G 或者 8G 内存就是够用的。如果打算用 TrueNAS 的话可以在预算范围内多购置一些内存，有关系统选择的内容我写在下面了。</p>
<blockquote>
<p>有必要 ECC 吗？可以，但没必要。随便买几根内存插上就行了，真想讲究的话就买同品牌同频率同型号的内存。</p>
</blockquote>
<h2 id="主板">主板</h2>
<p>主板要在预算范围内选靠谱一些的，劣质主板的供电可能会有问题，这对于我们这种 7*24 运行的机器来说是很大的问题了。</p>
<p>另外如果计划加的硬盘多的话要先看一下硬盘供电和 SATA 接口是不是够用，不够的话还要买 PCIE 转接卡。</p>
<h2 id="电源">电源</h2>
<p>电源更好选，我们选一个转换率达标的<strong>大牌</strong> 就好了，功率反而是最不重要的。另外我建议各位选购全模组电源，因为我们大概率是不会给 NAS 装显卡的，用上全模组电源就可以让机箱里少很大一坨线。</p>
<p>现在我用的就是非模组电源，机箱里一大坨一大坨的供电线闲着用不上，徒增散热难度。</p>
<h2 id="硬盘">硬盘</h2>
<p>硬盘就在淘宝上找那几个口碑好的店去买就好了，既然组 NAS 了我建议还是 4T 起步，8T 10T 16T 最好。</p>
<p>如果需要缓存盘的话，要考虑自己是否会上万兆，如果是万兆内网的话一定要上 nvme 的盘，否则 SATA 的 SSD 就可以用作缓存了。因为 SATA 3.0 的速度是 6 Gbps 要高于常见的千兆、2.5G 和 5G，但是不到万兆的 10G。</p>
<h2 id="网络">网络</h2>
<p>网络基本上有四个选择，大家可以根据自己的需求进行选择：</p>
<ul>
<li>Wi-Fi <strong>愚蠢之选</strong> ：速度慢且不稳定，NAS 系统对 Wi-Fi 的支持也不好，没有任何理由选择为 NAS 配置 Wi-Fi；</li>
<li>千兆 <strong>新手之选</strong> ：不改动网络，不新增设备，125mb/s 的速度能满足几乎所有功能性需求；</li>
<li>2.5G <strong>实用之选</strong> ：2.5G 的网卡和交换机都不算贵，能将内网速度提升一倍不止，性价比很高；</li>
<li>万兆 <strong>高玩之选</strong> ：如果经常有大量数据传输的需求，那可以咬咬牙上万兆，100G 的数据也能一分多钟搞定，不过一般玩家就不太建议这么搞了，太贵；</li>
</ul>
<blockquote>
<p>你说还有 40G ？散了散了，买不起了 🤷‍♂️</p>
</blockquote>
<h1 id="0x04-系统选择">0X04 系统选择</h1>
<p>自组 NAS 的话基本上就下面这几种系统方案：</p>
<ul>
<li>TrueNAS Core <strong>稳如老狗</strong> ：企业级的 NAS 系统，基于 BSD，原生 ZFS，稳如老狗。不过没什么可玩性，如果是用作纯 NAS 的话可以考虑；</li>
<li>TrueNAS SCALE <strong>稳中带皮</strong> ：同样的企业级 NAS 系统，基于 Linux，也很稳定，比 Core 版的可玩性强一些，带 Docker；</li>
<li>OMV <strong>简单粗暴</strong> ：一个相对简单的系统，基于 Debian，没有深度用过，不过用户量也不是很大；</li>
<li>WIndows Server <strong>熟悉的地方</strong> ：有些用户对 Windows 很熟悉，对 Linux 则一窍不通，那其实装个 Windows 开启文件共享也挺好的，还免了后续的折腾；</li>
<li>Linux <strong>硬核之选</strong> ：如果你对自己的 Linux 技术有信心，是可以直接装 Linux 然后自己配置文件共享的，这样还更自由，只是 web 面板的缺失会导致修改配置和部署服务的麻烦程度直线提升；</li>
<li>Unraid <strong>玩家之选</strong> ：Unraid 是除了 Windows 以外唯一一个付费系统，可以方便的配置 Docker 和虚拟机，也有应用商店可以快速安装一些诸如 Plex、qbittorrent 之类的应用；</li>
</ul>
<p>按个人使用经验来说，比较推荐 <strong>TrueNAS SCALE</strong> 和 <strong>Unraid</strong> 两个。</p>
<h2 id="truenas-scale">TrueNAS SCALE</h2>
<p>优势：</p>
<ol>
<li>开源且免费</li>
<li>ZFS 很屌</li>
<li>带有插件市场，方便安装插件</li>
<li>支持在 NAS 上部署虚拟机</li>
</ol>
<p>劣势：</p>
<ol>
<li>上手难度较高</li>
<li>ZFS 并不适合所有人</li>
<li>ZFS 对内存要求较大</li>
<li>插件市场并不很完善</li>
</ol>
<h2 id="unraid">Unraid</h2>
<p>优势：</p>
<ol>
<li>阵列系统自由度高</li>
<li>上手门槛低</li>
<li>插件市场相比 TrueNAS 更完善</li>
<li>中文化做的更好</li>
<li>管理界面更加直观</li>
<li>也能部署虚拟机</li>
</ol>
<p>劣势：</p>
<ol>
<li>要钱，现在还改成了订阅制（可以去咸鱼收老的激活码）</li>
<li>对 ZFS 支持不佳</li>
<li>在使用校验盘且没有缓存的情况下写入速度慢</li>
</ol>
<h1 id="0x05-阵列介绍unraid-only">0X05 阵列介绍（Unraid Only）</h1>
<p>这里简单介绍一下 Unraid 的阵列，严格来说不叫阵列，应该是 Array。</p>
<p></p>
<p>我们以 3 块 8T 的硬盘为例，如果组成无校验的 Array，可用空间就是 3*8=24T。向其中存储的文件会<strong>以文件为尺度分散在所有硬盘中</strong> ，这种方式的特点就是：<strong>读写的速度都是单盘的速度</strong> 。并且数据安全性上也比较特别，由于都是以文件为尺度进行分盘的，所以即使 3 块盘坏了 2 块，那活着的盘里的数据也还能都取出来，极端点说 100 快盘坏了 99 个，最后那个活着的也能读数据出来。这就是 Unraid 的特性。</p>
<p></p>
<p>还是 3 块 8T 的盘，如果将其中一个用作<strong>校验盘</strong> ，那可用空间就是 2*8=16T。存储的文件依旧以文件为尺度分散在硬盘中，但是每次写入数据到「数据盘」时，都会同时计算校验值写入「校验盘」。我们假设数据盘 A 存储了<code>[01010101]</code>的数据，数据盘 B 存储了 <code>[01100110]</code> 的数据，那经过计算我们校验盘就会存储 <code>[00110011]</code>（通过计算对应位置的二进制得到的）。这样一来 2 块数据盘无论坏掉哪一个，都可以根据另一个好的和校验盘进行计算将其数据恢复出来；如果校验盘坏了，那数据本身就没有丢，再替换一块校验盘上去即可。带校验的模式也有一点风险，就是「如果只有校验盘活下来」的情况，这种情况虽然校验盘活下来了，但是数据还是全都丢完了。</p>
<p>一般来说你都用 NAS 了，想必是对数据安全有一定要求的，所以建议 Unraid 配合校验盘一起使用，担心性能问题大不了再加一个缓存盘就是了。</p>
<h1 id="0x06-阵列介绍truenas-only">0X06 阵列介绍（TrueNAS Only）</h1>
<p>选择 TrueNAS 肯定是要用 ZFS 的，我们一般用 ZFS 也就这几种用法：strpe, mirror, raid-z, raid-z2。严格来说这些阵列方案和常见的 RAID 是不一样的，但也大差不差，所以我还是写了这个简易的对照表，方便各位理解。</p>
<table>
  <thead>
      <tr>
          <th>ZFS Name</th>
          <th>RAID Name</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>strpe</td>
          <td>raid-0</td>
      </tr>
      <tr>
          <td>mirror</td>
          <td>raid-1</td>
      </tr>
      <tr>
          <td>raid-z</td>
          <td>raid-5</td>
      </tr>
      <tr>
          <td>raid-z2</td>
          <td>raid-6</td>
      </tr>
  </tbody>
</table>
<p>还是那句话，你都用 NAS 了，想必是对数据安全有一定要求的，所以直接抛弃 strpe 这种一损俱损的疯狂模式，我们从 mirror 开始介绍。</p>
<p>mirror 是最简单的，就是纯镜像。我们依旧假设你有 3 个 8T 盘，现在将他们组成 ZFS mirror 之后可用空间就只有 8T，但是安全性暴涨。mirror 模式会将写入阵列的数据同时写入到所有磁盘，也就是说每个盘里都有完整的数据，这样一来 3 块盘只要没有一起挂掉，那数据就全部还在，是<strong>数据安全性最高</strong> 的。</p>
<p>raid-z 则是带校验的，但是与 Unraid 不同，<strong>raid-z 不存在校验盘的概念</strong> 。三块盘的身份是相同的，功能也是一样的，你写入的数据会分散在两块盘中，再将校验数据写入另一块盘。这种方式乍一看和 Unraid 上使用单个校验盘是一样的，但其实大相径庭。由于数据分散在三块盘中，校验数据也分散在三块盘中，这就意味着读写都是三块盘一起工作的，所以<strong>性能比带校验的 3 盘 Unraid 强</strong> 好多。但是当同时坏掉两块盘的时候，不能像 Unraid 一样有概率恢复一半数据。</p>
<p>raid-z2 则是带两个校验的，通常只有硬盘数更多时（例如 5 块）才会考虑，原理同上。带两个校验盘就意味着整个阵列中可以坏掉随意两块盘。</p>
<h1 id="0x07-装都装了-跑个服务吧">0X07 装都装了 跑个服务吧</h1>
<p>如果你的 NAS 性能比较强，有多余的性能可以跑一些服务的话，我可以推荐一下我部署的服务：</p>
<ul>
<li>Plex 影音中枢，可以将自己下载好的电影电视剧做成海报墙，并且在多个设备上无间断播放，需要在电视电脑平板手机等多设备上观看的话还是很好用的；</li>
<li>FileBrowser 文件管理器，虽然可以通过 SMB 协议挂载目录到手机电脑上，但偶尔不方便挂载的时候可以用它管理文件；</li>
<li>cailbre-web 电子书管理器，类似于 Plex，不过它是针对电子书的，可以在线看书、管理、收藏；</li>
<li>firefox 有点离谱，但是 Firefox 可以跑在浏览器里，我把 Firefox 通过 frp 做了内网透传，这样人在外面只需要访问这个 Firefox 服务就能间接访问家里部署的所有 web 服务了；</li>
<li>frp 内网穿透，允许你通过自建的服务器转发流量到家中，实现远程访问家里 NAS 的功能；</li>
<li>homeassistant 智能家居，还没深度使用，不过多介绍；</li>
<li>netdata 性能监控，说实话没什么用，但是看着帅；</li>
<li>qbittorrent BT 下载神器，没有介绍的必要；</li>
<li>SpeedTest 测速工具，用来测试内网速度是否达标</li>
</ul>
<h1 id="0x08-冷静消费">0X08 冷静消费</h1>
<p>一波分析后蠢蠢欲动？<strong>冷静，冷静，冷静</strong></p>
<p>开搞之前先问自己几个问题：</p>
<ol>
<li>真的有那么多的文件要存储吗？</li>
<li>真的有那么多的数据要备份吗？</li>
<li>真的有那么多的设备要访问吗？</li>
<li>电脑加硬盘的方案真的不行吗？</li>
</ol>
<p>如果真的都考虑清楚了，那就开搞吧～</p>
<p>最后提醒一句<strong>数据无价，做好备份</strong></p>
]]></description></item></channel></rss>