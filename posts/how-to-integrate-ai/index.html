<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>如何高质量地接入 AI - Shawn's blog</title><meta name=Description content="分享我的知识、经验、生活与感悟"><meta property="og:url" content="https://blog.programmer.work/posts/how-to-integrate-ai/"><meta property="og:site_name" content="Shawn's blog"><meta property="og:title" content="如何高质量地接入 AI"><meta property="og:description" content="0X00 没有什么意义但我就是想写的前言 有一说一现在的大模型发展太快了，最开始我列这个大纲的时候是把 deepseek 作为「凑合能用但超级便宜」的一个国产替代品来介绍的，没想到过了个年它直接翻身了，现在甚至能打 GPT-4o。所以我决定现在立刻马上把这篇文章写完，否则没准又杀出来个什么模型，会导致我永远写不完了 🤣"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-06T14:20:00+00:00"><meta property="article:modified_time" content="2025-02-07T02:23:03+00:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="LLM"><meta property="og:image" content="https://blog.programmer.work/logo.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.programmer.work/logo.png"><meta name=twitter:title content="如何高质量地接入 AI"><meta name=twitter:description content="0X00 没有什么意义但我就是想写的前言 有一说一现在的大模型发展太快了，最开始我列这个大纲的时候是把 deepseek 作为「凑合能用但超级便宜」的一个国产替代品来介绍的，没想到过了个年它直接翻身了，现在甚至能打 GPT-4o。所以我决定现在立刻马上把这篇文章写完，否则没准又杀出来个什么模型，会导致我永远写不完了 🤣"><meta name=application-name content="Shawn's blog"><meta name=apple-mobile-web-app-title content="Shawn's blog"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://blog.programmer.work/posts/how-to-integrate-ai/><link rel=prev href=https://blog.programmer.work/posts/2024-summary/><link rel=next href=https://blog.programmer.work/posts/macos-bad-apple/><link rel=stylesheet href=/css/style.min.658eb25b73ad29ab864a36ed014516c5047802d1ff98d0080132d1abe1332f5b.css integrity="sha256-ZY6yW3OtKauGSjbtAUUWxQR4AtH/mNAIATLRq+EzL1s="><link rel=preload href=/lib/fontawesome-free/all.min.0df5a33710e433de1f5415b1d47e4130ca7466aee5b81955f1045c4844bbb3ed.css integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.0df5a33710e433de1f5415b1d47e4130ca7466aee5b81955f1045c4844bbb3ed.css integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0="></noscript><link rel=preload href=/lib/animate/animate.min.5fbaeb9f8e25d7e0143bae61d4b1802c16ce7390b96ceb2d498b0d96ff4c853f.css integrity="sha256-X7rrn44l1+AUO65h1LGALBbOc5C5bOstSYsNlv9MhT8=" as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/animate/animate.min.5fbaeb9f8e25d7e0143bae61d4b1802c16ce7390b96ceb2d498b0d96ff4c853f.css integrity="sha256-X7rrn44l1+AUO65h1LGALBbOc5C5bOstSYsNlv9MhT8="></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"如何高质量地接入 AI","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/blog.programmer.work\/posts\/how-to-integrate-ai\/"},"genre":"posts","keywords":"AI, LLM","wordcount":4667,"url":"https:\/\/blog.programmer.work\/posts\/how-to-integrate-ai\/","datePublished":"2025-02-06T14:20:00+00:00","dateModified":"2025-02-07T02:23:03+00:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Shawn"},"description":""}</script></head><body data-header-desktop=auto data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"dark"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"dark"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Shawn's blog">Shawn's blog</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/about/>关于 </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Shawn's blog">Shawn's blog</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/about/ title>关于</a><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">如何高质量地接入 AI</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://blog.programmer.work title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>Shawn</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2025-02-06>2025-02-06</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;约 4667 字&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;预计阅读 10 分钟&nbsp;</div></div><div class="details toc" id=toc-static data-kept=true><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#chatgpt>ChatGPT</a></li><li><a href=#claude>Claude</a></li><li><a href=#豆包>豆包</a></li><li><a href=#deepseek>deepseek</a></li><li><a href=#kimi>kimi</a></li><li><a href=#poe>POE</a></li><li><a href=#综合>综合</a></li></ul><ul><li><a href=#模型选择>模型选择</a></li><li><a href=#如何接入>如何接入</a></li></ul><ul><li><a href=#glarity>glarity</a></li><li><a href=#chatgpt-next-web>ChatGPT-Next-Web</a></li><li><a href=#obsidian>Obsidian</a></li></ul></nav></div></div><div class=content id=content><h1 id=0x00-没有什么意义但我就是想写的前言>0X00 没有什么意义但我就是想写的前言</h1><p>有一说一现在的大模型发展太快了，最开始我列这个大纲的时候是把 deepseek 作为「凑合能用但超级便宜」的一个国产替代品来介绍的，没想到过了个年它直接翻身了，现在甚至能打 GPT-4o。所以我决定现在立刻马上把这篇文章写完，否则没准又杀出来个什么模型，会导致我永远写不完了 🤣</p><p>这篇文章的主要受众群体如下：</p><ol><li>知道最近 AI 很火，想用用看但是不知道怎么上手的朋友</li><li>尝试用过一些大模型，但是觉得接入不方便或者价格高的朋友</li><li>想全面接入 AI，让 AI 成为自己得力助手的朋友</li></ol><p>这篇文章会介绍这些内容：</p><ol><li>成品工具：只需要一个浏览器或者一个 APP 即可访问的最大众化的 AI 接入模式</li><li>模型选择：列举常见模型的特点，根据你的需求选择合适的大模型</li><li>API 接入：不方便接入原生 Claude/OpenAI API 时的优秀替代品</li><li>三方工具：通过 API 接入后能大幅改善日常使用体验的一些工具</li><li>本地部署：有关本地部署的一些个人看法</li></ol><p>那么废话少说，现在开始正文了</p><h1 id=0x01-商业化成品工具>0X01 商业化成品工具</h1><p>想要最快速的接入 AI 能力，那首选的自然是现成的商业化的 2C 产品了，所以我这里收集了几个我自己用过的比较好用的的商业化成品工具。</p><blockquote><p>注意这部分只讨论产品，不讨论模型，有关模型的讨论放在下面一个段落。</p></blockquote><h2 id=chatgpt>ChatGPT</h2><p>首先，自然是目前大模型的领军人物 OpenAI 了，它的 ChatGPT 目前应该是全球范围内最知名的 AI 工具了。目前 ChatGPT 提供了多种模型可选，也提供了多模态模型和联网搜索功能，部分高级模型需要付费使用，费用一般是 $20/mon。</p><blockquote><p>在 PC/Mac/Android 上使用 ChatGPT 需要有正确的上网姿势，在 iPhone 上还需要一个海外 Apple ID。并且注册起来也比较麻烦。如果切实需要的话可以在网上自行搜索一下注册教程。</p></blockquote><ul><li>访问方式：web、app、PC/Mac 客户端</li><li>优势：APP 使用体验极佳、够聪明、多模态；</li><li>劣势：访问难度高、价格贵；</li></ul><p>综合推荐等级：★★★★☆</p><h2 id=claude>Claude</h2><p>Claude 是追着 ChatGPT 打的另一个海外巨头，个人认为综合能力上略次于 ChatGPT 但不明显。不过同样的注册、访问都会有些麻烦。但是有一个上下文超长且比较便宜的模型（Claude-3.5-sonset-200k），可以让他阅读超长的 pdf、 MS office 等文档。同样的提供了更高级的付费模型，价格为 $20/mon。</p><ul><li>访问方式：web、app、PC/Mac 客户端</li><li>优势：聪明、多模态、比 ChatGPT 访问轻松一些；</li><li>劣势：访问难度依然较高、价格贵；</li></ul><p>综合推荐等级：★★★☆☆</p><h2 id=豆包>豆包</h2><p>豆包是字节跳动旗下的 AI 工具，目前我亲测下来说实话聪明程度明显弱于 ChatGPT/Claude，但是它强就强在免费和体验优良。首先它内置了很多个不同 prompt 的「人」，可以作为你的助手，这一点对于不会写 prompt 的新手来说很是实用。手机的 APP 还能通过语音对谈的方式和豆包交流，虽然 ChatGPT 也有这个功能，但是在国内使用豆包反应更快并且口语听起来舒服很多很多。macOS 上的客户端可以启用一些插件功能，实现划选文字进行翻译、解释等功能。</p><ul><li>访问方式：web、app、PC/Mac 客户端</li><li>优势：多模态、接入容易、语音体验良好、内置 prompt、免费；</li><li>劣势：不够聪明、进阶使用体验较差；</li></ul><p>综合推荐等级：★★★★☆</p><blockquote><p>建议所有人在手机上装一个豆包，毕竟是免费的，有事没事跟他硬聊几句都还是划算的。而且它也能联网，所以快速搜索一些确定有结果的问题也很好用。</p></blockquote><h2 id=deepseek>deepseek</h2><p>deepseek 这几天可真是爆了（以至于我一直在用的超快的 API 突然变慢了 😮‍💨）。简单介绍一下 deepseek 也是国产的，他们最擅长使用超低的成本做相同的事，最近刷屏的新闻也正是他们用了 GPT-o1 大概 2% 的成本训练出来了几乎相同水平的 DeepSeek-R1 模型。目前来说 deepseek 的重心还是在技术上，所以他们的客户端/web依旧停留在「能用」的水平线上。</p><ul><li>访问方式：web、app</li><li>优势：免费、多模态、接入容易、聪明；</li><li>劣势：应用层做的不够好、使用人数激增导致响应变慢；</li></ul><p>综合推荐等级：★★★★☆</p><h2 id=kimi>kimi</h2><p>kimi 是比较早火起来的国产 AI，当时的主要卖点是联网搜索。</p><ul><li>访问方式：web、app</li><li>优势：免费、多模态、接入容易、联网搜索能力强、app 体验好；</li><li>劣势：不如 DeepSeek-R1 聪明；</li></ul><p>综合推荐等级：★★★☆☆</p><h2 id=poe>POE</h2><p><strong>POE：我们不生产模型，我们只是大模型的搬运工</strong></p><p>POE 是一个集成了大量模型第三方应用，在这里可以付一份钱同时使用几乎所有的热门模型。例如你想同时使用 ChatGPT 和 Claude 的高级模型，觉得同时买两个会员太贵了，就可以同样花 $20 购买 POE 的会员，这样一来就可以同时访问他们了。但需要注意的是，POE 的逻辑是会员每月送你 1000000 「点数」，每次对话会根据模型的不同消耗不同的点数（一般都是够用的，我比较高强度使用都是够的）。这也是我目前唯一付了年费的 AI 订阅项。</p><ul><li>访问方式：web、app、PC/Mac 客户端</li><li>优势：访问所有热门模型（包括文生图模型）</li><li>劣势：付费、使用次数有限（尽管限制很宽松）</li></ul><p>综合推荐等级：★★★★☆</p><h2 id=综合>综合</h2><p>综合看下来，我可以做出下面的推荐：</p><ul><li>如果你只是想用最简单的方式体验一下AI，并且希望它足够简单易用，那就选豆包</li><li>如果你想使用目前最强的免费 AI 模型，同时愿意学习 AI 的用法，那就选 deepseek</li><li>如果你想接入世界先进的 AI 模型，那就考虑订阅 ChatGPT（ChatGPT 如果不订阅的话不如直接用 deepseek）</li><li>如果你想体验更多热门模型，想要了解不同模型的区别和擅长的方向，也想要深入学习使用大模型，那建议订阅 POE</li></ul><h1 id=0x02-通过-api-接入>0X02 通过 API 接入</h1><p>上面我们聊的都是点击即用的成熟的商业化产品，现在来讨论一下通过 API 来接入这些模型。</p><blockquote><p>提示：如果你听不懂 <code>API</code>、<code>base_url</code>、<code>API KEY</code>、<code>HTTP Method</code>、这几个词就意味着你暂时不适合下面的内容，继续阅读下去可能会感到有些蒙圈，这是正常现象 🤣</p></blockquote><p>首先我来介绍一下为什么我们需要通过 API 接入大模型，有如下几个优势：</p><ul><li>价格：例如 ChatGPT 的价格是 $20 每月，如果你只是每天对话个十次八次的，直接开通 Plus 会显得很亏，因为 ChatGPT Plus 是按月付费的。但是 API 则是按量付费，计费方式从每月固定额度变成了根据交互的 tokens 数量计算，在用量不大的情况下会更便宜；</li><li>性能：虽然没有直接证据，但是我体感上各家的 2C 产品使用的服务器和 2B 的 API 使用的服务器并非同一组，手机 APP 访问已经在卡了但是通过 API 访问就还是比较快；</li><li>定制：通过 API 访问可以自己调整更多的参数，例如影响记忆力和费用的 <code>max_tokens</code> 和影响输出的 <code>temperature</code> 等；</li><li>体验：使用 API 访问即使只是使用最基础的对话功能，我们也有多个前端工具可以选择，不会像官方的客户端一样没有半点定制化空间；</li><li>扩展：我们可以将 API KEY 配置到很多支持的工具上，让工具们获得 AI 的能力加持（例如 obsidian、Firefox/Chrome 等）；</li></ul><h2 id=模型选择>模型选择</h2><p>目前通过 API 接入的话我个人只推荐 deepseek、GPT、Claude 这三个。下面是每个家族的代表和他们的能力（主观评价）和价格的对比。</p><table><thead><tr><th>名称</th><th>能力（5分制）</th><th>上下文</th><th>输入价格（每百万 Tokens）</th><th>输出价格（每百万 Tokens）</th><th>备注</th></tr></thead><tbody><tr><td>DeepSeek V3</td><td>3</td><td>64k</td><td>$0.27</td><td>$1.10</td><td>价格无敌，配置在浏览器扩展上用于翻译和总结非常合适</td></tr><tr><td>DeepSeek R1</td><td>4.5</td><td>64k</td><td>$0.55</td><td>2.19</td><td>性价比无敌，能力媲美贵它将近 30 倍的 GPT-o1</td></tr><tr><td>GPT-4o</td><td>3.5</td><td>128k</td><td>$2.5</td><td>$10</td><td>-&ndash;</td></tr><tr><td>GPT-o1</td><td>4.5</td><td>200k</td><td>$15</td><td>$60</td><td>-&ndash;</td></tr><tr><td>Claude-3.5-sonset</td><td>4</td><td>200k</td><td>$3</td><td>$15</td><td>-&ndash;</td></tr></tbody></table><p>目前我自己的体验下来，推荐如下：</p><ul><li>DeepSeek V3 价格最便宜，充 10 块钱可以用很久。适合将它配置到一些支持 AI 的工具上，用来总结文章、大段翻译等。虽然它不够聪明但是足够便宜，随便调用也不用心疼自己的钱包；</li><li>DeepSeek R1 目前使用体验良好，足够聪明价格也是很便宜。如果不嫌弃它每次都要思考半天的话（其实这是它的优势项），可以作为主力 AI 模型使用，它理论上更擅长数学、编程等逻辑性强的工作；</li><li>GPT-4o 是传统模型中很强的了，没有 o1 和 R1 的推理过程，反应比较迅速。价格虽然比较贵但多少能承受，也是主力 AI 模型的一个优秀备选；</li><li>GPT-o1 应该是这些模型里理论最强的，但是这个价格嘛也很离谱。如果你在意它比 R1 强的那一点能力且不在意这 30 倍的价差，那 GPT-o1 是个不错的选择；</li><li>Claude-3.5-sonset 最大的优势是 200k 的上下文，是目前热门模型中上下文窗口最大的一个。如果你经常有大上下文的需求那么 Claude-3.5-sonset 是一个优秀的选择；</li></ul><blockquote><p>有关 tokens 和上下文：</p><p>我们在和大模型交互的时候，我们自己说的文字和大模型返回的文字都会被分词，然后将分词之后的结果作为 token 计算。例如我给模型提供一个 10 万个汉字的文档，让他回答我的一个问题，AI 的回答大概是 1000 个汉字的话，大约会消耗掉 10 万个 tokens。</p><p>上下文则是我们和模型对话时 AI 能处理的最大 tokens 数量。上面的例子一次对话就需要消耗 10 万个 tokens 也就是 100k 左右，也就意味着 DeepSeek V3/R1 都无法处理这个对话请求，但是 GPT-4o/o1 和 Claude-3.5-sonset 都能处理。</p></blockquote><h2 id=如何接入>如何接入</h2><p>众所周知，接入 AWS 的 API 就需要 AWS 的账号，但是现在的 AI 接入方式多少有些不一样的地方。当然通过 OpenAI 官方接入 OpenAI 的模型是天经地义的，但是我们国内用户光是注册 OpenAI 和 Claude 的账号就已经很费劲了，后面付费还有一座大山拦路，着实是整不动。所以在官方接入的传统方式之外还可以通过转发站点实现 API 接入，这种接入方式不仅注册和付费更轻松，还会有些许优惠。这里介绍两个站点：<a href=https://burn.hair/ target=_blank rel="noopener noreffer">头顶冒火</a> 和 <a href=https://gpt302.saaslink.net/M8oaa5 target=_blank rel="noopener noreffer">302.ai</a>，这两个平台类似，都是类似于前面介绍的 POE 的平台，只不过这两个平台提供的是聚合的 API 服务，在这一处充值后能通过 API 访问平台支持的模型。</p><p>如果你想通过 API 的方式接入 DeepSeek 的话就不需要再用上面的服务中转了，直接去官网注册账号然后支付宝微信付款用就行了。</p><blockquote><p>另外有个好消息，目前已知的绝大多数大模型的 API 都兼容 OpenAI 的 API 标准，也就意味着绝大多数能使用 OpenAI API 的工具都能通过修改 <code>base_ur</code>, <code>API KEY</code>, <code>model</code> 这三个参数的方式快速接入。</p></blockquote><h1 id=0x03-第三方工具>0X03 第三方工具</h1><p>使用第三发工具的前提是通过 API 访问大模型，个人认为这才是当前大模型的完整使用方式。下面介绍几个自己真正用过的第三方工具：</p><h2 id=glarity>glarity</h2><p>这是一个浏览器扩展，配置好 API 之后它会有一个悬浮按钮在浏览器里，可以一键快速调用大模型对当前页面进行总结，也可以针对当前页面进行提问，还可以做到在尽力维持页面布局的情况下实现逐行翻译。强烈推荐所有可以通过 API 访问大模型的朋友安装试用。</p><h2 id=chatgpt-next-web>ChatGPT-Next-Web</h2><p>这是一个简单的聊天工具，不管是 DeepSeek 还是 ChatGPT 他们都有自己的页面，但是通过 API 访问的话总不能就在命令行里用吧。所以 ChatGPT-Next-Web 就出现了，它就是一个可以创建多个对话也能上传文件的前端工具，给它配好 API 就能像普通客户端一样使用 API 了。值得表扬的是这个开源项目可以部署在服务器上，通过浏览器访问，效果非常棒。也就意味着你可以自己开通 API 后把它部署在公网服务器上，配置一个密码，就能让自己和家人朋友一起用了。</p><h2 id=obsidian>Obsidian</h2><p>如果你也用 Obsidian 的话可以给你推荐一个名为 Text Generator 的插件，这个插件配置好之后可以在 Obsidian 中调用 API。可以实现的功能包括但不限于：选中大段文字让他检查错误、总结整篇笔记、生成某某的介绍等。虽然不如 Notion 的 Notion AI 集成度那么高，但是体验也还是不错的。</p><h1 id=0x04-本地化部署>0X04 本地化部署</h1><p>最后再聊一聊本地部署吧，最开始的时候我尝试过在 MacBook 上部署 Llama 3.1 的 7B 和 14B 模型测试。最近 DeepSeek R1 的突然爆火也开始出现了大量的本地部署的教程，给人一种在本地部署之后就不需要联网使用官方服务的感觉。</p><p>我自己测试的硬件配置是一台 M2 Max 32G 的 MacBook Pro，按理说跑大模型的性能应该是超出大多数朋友的电脑的。就以最近我测试的 DeepSeek R1 为例，简单测试的结果如下：</p><table><thead><tr><th>模型</th><th>效果</th><th>速度</th></tr></thead><tbody><tr><td>DeepSeek R1 7B</td><td>一般</td><td>飞快</td></tr><tr><td>DeepSeek R1 14B</td><td>一半</td><td>飞快</td></tr><tr><td>DeepSeek R1 32B</td><td>可以非严肃环境使用</td><td>比较快</td></tr><tr><td>DeepSeek R1 70B</td><td>跑不动</td><td>跑不动</td></tr></tbody></table><p>并且即使我跑 32B 这样的模型，效果也并不够看。所以我自己的个人看法就是：</p><ul><li>如果你只能跑 7B 或者 14B 的模型，那可以用来学习、体验、图一乐</li><li>如果你能跑 32B 的模型，那可以用来正经聊聊，但是能力依旧有限，不适合严肃环境使用</li><li>如果你能跑 70B 的模型，那&mldr;&mldr;我没试过，不知道能力怎么样 🤣</li><li>如果你能跑 671B 的模型，那请你联系我，我想和土豪做朋友</li></ul><p>如果要在本地部署的话，目前比较推荐的就只有 DeepSeek 和 Llama 了，并且在模型选择上基本 32B 就到头了，如果是自己本地跑跑玩玩的话建议从 7B 和 14B 中进行选择，最多最多试试 70B（如果是 Mac 的融合内存的话）。</p><blockquote><p>最后悄悄说一下，本地部署的话可以了解一下带有 <code>abliterated</code> 标签的模型，这才是本地部署模型最大的意义。</p></blockquote></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2025-02-07</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/ai/>AI</a>,&nbsp;<a href=/tags/llm/>LLM</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/2024-summary/ class=prev rel=prev title="2024 年度总结"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>2024 年度总结</a>
<a href=/posts/macos-bad-apple/ class=next rel=next title="苹果里的虫子：macOS 的几个臭毛病">苹果里的虫子：macOS 的几个臭毛病<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div><div id=comments><div id=gitalk class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://github.com/gitalk/gitalk></a>Gitalk</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>Shawn 💗 Amber</div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2015 - 2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=https://blog.programmer.work target=_blank>Shawn</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=/lib/gitalk/gitalk.min.7a92033a32beba2a57cd417e2d5ab7ac2a45bf5111227648ac274b81e6a6cf57.css integrity="sha256-epIDOjK+uipXzUF+LVq3rCpFv1ERInZIrCdLgeamz1c="><link rel=stylesheet href=/lib/katex/katex.min.76e39bd605d45b2d1944123c66608b0c8bb9baeb70720b212571531c7cf9bc2a.css integrity="sha256-duOb1gXUWy0ZRBI8ZmCLDIu5uutwcgshJXFTHHz5vCo="><link rel=stylesheet href=/some.4187f1011616875f9033a8af97475eb55b97ed2f80267e22df0cd8305de45cc8.css integrity="sha256-QYfxARYWh1+QM6ivl0detVuX7S+AJn4i3wzYMF3kXMg="><script type=text/javascript src=/lib/gitalk/gitalk.min.3e68fce688cb68f396c11b65309c267b307f420f01cef269e5e4f3bd769801f0.js integrity="sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.3d9120fa621da6d613c1698b7014ec6bdf4620366e8f2b7b547059f4b6f6272b.js integrity="sha256-PZEg+mIdptYTwWmLcBTsa99GIDZujyt7VHBZ9Lb2Jys="></script><script type=text/javascript src=/lib/clipboard/clipboard.min.e17a1d816e13c0826e0ed7febfabc3277f45571234bde0bf9120829a7169edc9.js integrity="sha256-4XodgW4TwIJuDtf+v6vDJ39FVxI0veC/kSCCmnFp7ck="></script><script type=text/javascript src=/lib/katex/katex.min.eb18207487161674e717087c317db14ac1a62dadaecccb802499ce173bfeb739.js integrity="sha256-6xggdIcWFnTnFwh8MX2xSsGmLa2uzMuAJJnOFzv+tzk="></script><script type=text/javascript src=/lib/katex/contrib/auto-render.min.cb7f4ca60ed5dc3e258415f8c7a3b46d4a93578a52adf83011f18a7f190e7602.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI="></script><script type=text/javascript src=/lib/katex/contrib/copy-tex.min.52ce78fab4860d24ef22128a52ce24ca01368a9034457a565a1d3fccbab0ddbb.js integrity="sha256-Us54+rSGDSTvIhKKUs4kygE2ipA0RXpWWh0/zLqw3bs="></script><script type=text/javascript src=/lib/katex/contrib/mhchem.min.5c0a121a8b490afc85860a522347aeb34fb508c6b23044e5d29f6b2194227b51.js integrity="sha256-XAoSGotJCvyFhgpSI0eus0+1CMayMETl0p9rIZQie1E="></script><script type=text/javascript>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:50},comment:{gitalk:{admin:["shawn-bluce"],clientID:"Ov23ligzD7mU8WBsue6H",clientSecret:"a832d1ba967e3a40f5485aa05e2a9e76f2d77901",id:"2025-02-06T14:20:00Z",owner:"shawn-bluce",repo:"shawn-bluce.github.io",title:"如何高质量地接入 AI"}},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1}}</script><script type=text/javascript src=/js/theme.min.612a51a43205bbcf3b4af348dc2e8aa60f77f4fe5535ebc57f13054b61607d6c.js integrity="sha256-YSpRpDIFu887SvNI3C6Kpg939P5VNevFfxMFS2FgfWw="></script></body></html>